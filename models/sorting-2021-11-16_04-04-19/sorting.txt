============================ Raw Args ============================
Namespace(batch_size=64, classification='y', dropout='n', dropout_prob=0.0, gpu_i=-1, imbalanced_sampler='n', k_folds='5', l2_reg='n', load_trained='n', log_dest='../models/sorting-2021-11-16_04-04-19', loss_freq=2, lr=0.005, model_name='SortingClassifier128', normalize='n', num_classes=5, num_epochs=20, optim='SGD', regression='n', root_dir='none', session_name='sorting', test_data_dir='none', test_labels_csv='none', train_data_dir='none', train_labels_csv='none', trained_path='../models/PMR_detection_0-3_two_to_one-2021-09-01_12-09-14/BEST_model.pth', val_freq=0, weight_decay_amnt=0.0, weighted_loss='n')



================================ Start Training ================================

Session Name: sorting

Model Name: SortingClassifier128
Device: cpu

Hyperparameters:
Batch Size: 64
Learning Rate: 0.005
Number of Epochs: 20
Normalization:n


FOLD 0
=================================================================
Train Epoch: 0 Iteration: 2 [128/225 (67%)]	 Batch 2 Loss: 1.584468


----------------- Epoch 0 -----------------

validation computation time: 0.0  minutes
tensor([[-3.7502e-02, -1.3518e-01, -2.0262e-01,  8.4481e-02, -1.0118e-01],
        [ 4.9173e-03, -1.7617e-01, -2.1947e-01,  9.1960e-03, -1.6570e-01],
        [ 7.7174e-03, -1.9388e-01, -2.2109e-01,  2.1270e-02, -1.9199e-01],
        [-2.4686e-02, -2.6973e-01, -2.9306e-01,  3.1847e-02, -2.7800e-01],
        [ 4.9173e-03, -1.7617e-01, -2.1947e-01,  9.1960e-03, -1.6570e-01],
        [ 1.3286e-02, -3.0699e-01, -3.5002e-01,  7.6721e-02, -2.8243e-01],
        [-5.0856e-02, -1.8388e-01, -2.6632e-01,  7.9303e-03, -1.7827e-01],
        [ 1.0321e-02, -2.2881e-01, -2.5234e-01,  5.6919e-02, -2.0753e-01],
        [ 2.1286e-02, -2.0587e-01, -2.4557e-01,  5.5148e-02, -1.7541e-01],
        [-1.2658e-02, -2.4912e-01, -3.2223e-01,  5.3400e-02, -2.2540e-01],
        [-3.3580e-02, -1.4758e-01, -2.6795e-01,  4.7887e-02, -1.0737e-01],
        [ 3.7923e-02, -2.6156e-01, -2.5945e-01,  8.0928e-02, -2.3374e-01],
        [ 2.0365e-04, -2.8397e-01, -3.3292e-01,  6.1909e-02, -2.6490e-01],
        [-1.5860e-02, -2.4572e-01, -2.8937e-01,  3.7399e-02, -2.3867e-01],
        [ 1.7971e-02, -2.6664e-01, -2.7670e-01,  6.6521e-02, -2.4390e-01],
        [ 4.7512e-03, -2.5293e-01, -2.7631e-01,  4.4862e-02, -2.4643e-01],
        [ 2.6183e-03, -2.9187e-01, -2.9755e-01,  1.0030e-01, -2.6501e-01],
        [ 7.6046e-03, -2.3791e-01, -3.1156e-01,  4.8206e-02, -2.0650e-01],
        [-3.0679e-02, -6.0265e-02, -1.2098e-01,  2.6286e-02, -4.1894e-02],
        [ 2.9235e-02, -1.5778e-01, -1.7357e-01,  2.5291e-02, -1.4026e-01],
        [ 1.0321e-02, -2.2881e-01, -2.5234e-01,  5.6919e-02, -2.0753e-01],
        [ 1.4057e-02, -2.3434e-01, -2.5183e-01,  5.6095e-02, -2.2131e-01],
        [-4.0670e-03, -1.7428e-01, -2.3302e-01,  9.1064e-02, -1.3494e-01],
        [-6.4009e-03, -1.4287e-01, -1.8725e-01,  5.5670e-02, -1.1942e-01],
        [ 2.8997e-03, -2.7167e-01, -3.2836e-01,  8.9252e-02, -2.2770e-01],
        [-5.0437e-02, -1.0058e-01, -1.7186e-01,  1.3772e-04, -1.2356e-01],
        [ 7.6046e-03, -2.3791e-01, -3.1156e-01,  4.8206e-02, -2.0650e-01],
        [-5.9467e-02, -1.0237e-01, -2.1459e-01,  2.5036e-02, -7.8520e-02],
        [-5.0618e-02, -1.2232e-01, -2.3928e-01,  7.0396e-02, -7.8205e-02],
        [-1.4950e-02, -2.5768e-01, -3.2974e-01,  5.1826e-02, -2.3609e-01],
        [-1.3871e-02, -1.9689e-01, -2.9954e-01,  1.0369e-01, -1.8197e-01],
        [-8.2308e-03, -2.6103e-01, -2.6802e-01,  1.2009e-01, -2.2820e-01],
        [-5.0959e-02, -1.4367e-01, -2.4949e-01,  3.2222e-02, -1.1845e-01],
        [-3.0116e-02, -2.9956e-01, -3.5603e-01,  3.5706e-02, -2.9612e-01],
        [-1.6608e-02, -1.5360e-01, -2.0826e-01,  4.7121e-02, -1.6875e-01],
        [ 3.6717e-03, -2.4525e-01, -2.7070e-01,  1.2193e-01, -2.0992e-01],
        [-3.9439e-02, -1.2990e-01, -1.7931e-01,  8.9808e-02, -1.0060e-01],
        [-2.1208e-02, -2.7250e-01, -3.6780e-01,  5.7073e-02, -2.4352e-01],
        [-7.0877e-03, -1.4548e-01, -2.0699e-01,  9.0595e-02, -1.0410e-01],
        [-7.4329e-03, -2.5209e-01, -3.2561e-01,  5.9444e-02, -2.2493e-01],
        [-5.9467e-02, -1.0237e-01, -2.1459e-01,  2.5036e-02, -7.8520e-02],
        [ 2.0365e-04, -2.8397e-01, -3.3292e-01,  6.1909e-02, -2.6490e-01],
        [-6.3863e-03, -2.8435e-01, -3.3774e-01,  4.0378e-02, -2.5988e-01],
        [-1.5074e-02, -1.6799e-01, -2.4749e-01,  4.6068e-02, -1.3947e-01],
        [ 5.6550e-03, -1.3822e-01, -1.4561e-01,  2.2103e-02, -1.3708e-01]])
tensor([4, 2, 2, 3, 2, 1, 1, 1, 3, 3, 0, 0, 1, 1, 0, 3, 3, 3, 2, 2, 1, 3, 4, 4,
        2, 0, 3, 2, 4, 3, 3, 3, 4, 1, 0, 3, 4, 1, 3, 1, 2, 1, 1, 4, 2])
Confusion Matrix
tensor([[ 0,  0,  1,  0,  0],
        [ 0,  0,  0,  0,  0],
        [ 0,  0,  0,  0,  0],
        [ 5, 11,  8, 13,  7],
        [ 0,  0,  0,  0,  0]])
class 0 accuracy: 0.0000%
class 1 accuracy: 0.0000%
class 2 accuracy: 0.0000%
class 3 accuracy: 100.0000%
class 4 accuracy: 0.0000%

Validation Loss: 1.5991, Accuracy: 13/225 (6%)
Training Loss:1.5998
Best Accuracy: 5.777778%
Time Elapsed: 0h 0m 6s

--------------------------------------------------------


================================ QUIT ================================
 Saving Model ...
