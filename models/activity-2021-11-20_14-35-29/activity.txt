============================ Raw Args ============================
Namespace(batch_size=32, classification='y', dropout='n', dropout_prob=0.0, gpu_i=-1, imbalanced_sampler='n', k_folds='4', l2_reg='n', load_trained='n', log_dest='../models/activity-2021-11-20_14-35-29', loss_freq=2, lr=0.005, model_name='ActivityFCN', normalize='n', num_classes=10, num_epochs=10, optim='Adam', regression='n', root_dir='none', session_name='activity', test_data_dir='none', test_labels_csv='none', train_data_dir='none', train_labels_csv='none', trained_path='n', val_freq=0, weight_decay_amnt=0.0, weighted_loss='n')



================================ Start Training ================================

Session Name: activity

Model Name: ActivityFCN
Device: cpu

Hyperparameters:
Batch Size: 32
Learning Rate: 0.005
Number of Epochs: 10
Normalization:n


FOLD 0
=================================================================
Train Epoch: 0 Iteration: 2 [64/60000 (0%)]	 Batch 2 Loss: 2.205732
Train Epoch: 0 Iteration: 4 [128/60000 (0%)]	 Batch 4 Loss: 2.366077
Train Epoch: 0 Iteration: 6 [192/60000 (0%)]	 Batch 6 Loss: 1.810467
Train Epoch: 0 Iteration: 8 [256/60000 (1%)]	 Batch 8 Loss: 1.958549
Train Epoch: 0 Iteration: 10 [320/60000 (1%)]	 Batch 10 Loss: 1.514140
Train Epoch: 0 Iteration: 12 [384/60000 (1%)]	 Batch 12 Loss: 1.194639
Train Epoch: 0 Iteration: 14 [448/60000 (1%)]	 Batch 14 Loss: 1.239343
Train Epoch: 0 Iteration: 16 [512/60000 (1%)]	 Batch 16 Loss: 0.913435
Train Epoch: 0 Iteration: 18 [576/60000 (1%)]	 Batch 18 Loss: 1.344948
Train Epoch: 0 Iteration: 20 [640/60000 (1%)]	 Batch 20 Loss: 0.853880
Train Epoch: 0 Iteration: 22 [704/60000 (2%)]	 Batch 22 Loss: 0.829971
Train Epoch: 0 Iteration: 24 [768/60000 (2%)]	 Batch 24 Loss: 0.601468
Train Epoch: 0 Iteration: 26 [832/60000 (2%)]	 Batch 26 Loss: 0.904963
Train Epoch: 0 Iteration: 28 [896/60000 (2%)]	 Batch 28 Loss: 0.908111
Train Epoch: 0 Iteration: 30 [960/60000 (2%)]	 Batch 30 Loss: 0.549200
Train Epoch: 0 Iteration: 32 [1024/60000 (2%)]	 Batch 32 Loss: 0.378047
Train Epoch: 0 Iteration: 34 [1088/60000 (2%)]	 Batch 34 Loss: 0.306874
Train Epoch: 0 Iteration: 36 [1152/60000 (3%)]	 Batch 36 Loss: 0.770245
Train Epoch: 0 Iteration: 38 [1216/60000 (3%)]	 Batch 38 Loss: 0.515697
Train Epoch: 0 Iteration: 40 [1280/60000 (3%)]	 Batch 40 Loss: 0.674732
Train Epoch: 0 Iteration: 42 [1344/60000 (3%)]	 Batch 42 Loss: 1.030451
Train Epoch: 0 Iteration: 44 [1408/60000 (3%)]	 Batch 44 Loss: 0.717679
Train Epoch: 0 Iteration: 46 [1472/60000 (3%)]	 Batch 46 Loss: 0.431123
Train Epoch: 0 Iteration: 48 [1536/60000 (3%)]	 Batch 48 Loss: 0.737035
Train Epoch: 0 Iteration: 50 [1600/60000 (4%)]	 Batch 50 Loss: 0.624478
Train Epoch: 0 Iteration: 52 [1664/60000 (4%)]	 Batch 52 Loss: 0.600609
Train Epoch: 0 Iteration: 54 [1728/60000 (4%)]	 Batch 54 Loss: 0.337291
Train Epoch: 0 Iteration: 56 [1792/60000 (4%)]	 Batch 56 Loss: 0.329414
Train Epoch: 0 Iteration: 58 [1856/60000 (4%)]	 Batch 58 Loss: 0.151849
Train Epoch: 0 Iteration: 60 [1920/60000 (4%)]	 Batch 60 Loss: 0.329265
Train Epoch: 0 Iteration: 62 [1984/60000 (4%)]	 Batch 62 Loss: 0.542549
Train Epoch: 0 Iteration: 64 [2048/60000 (5%)]	 Batch 64 Loss: 0.687564
Train Epoch: 0 Iteration: 66 [2112/60000 (5%)]	 Batch 66 Loss: 0.815791
Train Epoch: 0 Iteration: 68 [2176/60000 (5%)]	 Batch 68 Loss: 0.253023
Train Epoch: 0 Iteration: 70 [2240/60000 (5%)]	 Batch 70 Loss: 0.400802
Train Epoch: 0 Iteration: 72 [2304/60000 (5%)]	 Batch 72 Loss: 0.222617
Train Epoch: 0 Iteration: 74 [2368/60000 (5%)]	 Batch 74 Loss: 0.356592
Train Epoch: 0 Iteration: 76 [2432/60000 (5%)]	 Batch 76 Loss: 0.629458
Train Epoch: 0 Iteration: 78 [2496/60000 (6%)]	 Batch 78 Loss: 0.436062
Train Epoch: 0 Iteration: 80 [2560/60000 (6%)]	 Batch 80 Loss: 0.690753
Train Epoch: 0 Iteration: 82 [2624/60000 (6%)]	 Batch 82 Loss: 0.202928
Train Epoch: 0 Iteration: 84 [2688/60000 (6%)]	 Batch 84 Loss: 0.380690
Train Epoch: 0 Iteration: 86 [2752/60000 (6%)]	 Batch 86 Loss: 0.271767
Train Epoch: 0 Iteration: 88 [2816/60000 (6%)]	 Batch 88 Loss: 0.363232
Train Epoch: 0 Iteration: 90 [2880/60000 (6%)]	 Batch 90 Loss: 0.558239
Train Epoch: 0 Iteration: 92 [2944/60000 (7%)]	 Batch 92 Loss: 0.490308
Train Epoch: 0 Iteration: 94 [3008/60000 (7%)]	 Batch 94 Loss: 0.224621
Train Epoch: 0 Iteration: 96 [3072/60000 (7%)]	 Batch 96 Loss: 0.388304
Train Epoch: 0 Iteration: 98 [3136/60000 (7%)]	 Batch 98 Loss: 0.516975
Train Epoch: 0 Iteration: 100 [3200/60000 (7%)]	 Batch 100 Loss: 0.311591
Train Epoch: 0 Iteration: 102 [3264/60000 (7%)]	 Batch 102 Loss: 0.525491
Train Epoch: 0 Iteration: 104 [3328/60000 (7%)]	 Batch 104 Loss: 0.218325
Train Epoch: 0 Iteration: 106 [3392/60000 (8%)]	 Batch 106 Loss: 0.388549
Train Epoch: 0 Iteration: 108 [3456/60000 (8%)]	 Batch 108 Loss: 0.862374
Train Epoch: 0 Iteration: 110 [3520/60000 (8%)]	 Batch 110 Loss: 0.297920
Train Epoch: 0 Iteration: 112 [3584/60000 (8%)]	 Batch 112 Loss: 0.515611
Train Epoch: 0 Iteration: 114 [3648/60000 (8%)]	 Batch 114 Loss: 0.242667
Train Epoch: 0 Iteration: 116 [3712/60000 (8%)]	 Batch 116 Loss: 0.415457
Train Epoch: 0 Iteration: 118 [3776/60000 (8%)]	 Batch 118 Loss: 0.170822
Train Epoch: 0 Iteration: 120 [3840/60000 (9%)]	 Batch 120 Loss: 0.441845
Train Epoch: 0 Iteration: 122 [3904/60000 (9%)]	 Batch 122 Loss: 0.132891
Train Epoch: 0 Iteration: 124 [3968/60000 (9%)]	 Batch 124 Loss: 0.593326
Train Epoch: 0 Iteration: 126 [4032/60000 (9%)]	 Batch 126 Loss: 0.553453
Train Epoch: 0 Iteration: 128 [4096/60000 (9%)]	 Batch 128 Loss: 0.310310
Train Epoch: 0 Iteration: 130 [4160/60000 (9%)]	 Batch 130 Loss: 0.247859
Train Epoch: 0 Iteration: 132 [4224/60000 (9%)]	 Batch 132 Loss: 0.659895
Train Epoch: 0 Iteration: 134 [4288/60000 (10%)]	 Batch 134 Loss: 0.190863
Train Epoch: 0 Iteration: 136 [4352/60000 (10%)]	 Batch 136 Loss: 0.305841
Train Epoch: 0 Iteration: 138 [4416/60000 (10%)]	 Batch 138 Loss: 0.157469
Train Epoch: 0 Iteration: 140 [4480/60000 (10%)]	 Batch 140 Loss: 0.395161
Train Epoch: 0 Iteration: 142 [4544/60000 (10%)]	 Batch 142 Loss: 0.373684
Train Epoch: 0 Iteration: 144 [4608/60000 (10%)]	 Batch 144 Loss: 0.261256
Train Epoch: 0 Iteration: 146 [4672/60000 (10%)]	 Batch 146 Loss: 0.258506
Train Epoch: 0 Iteration: 148 [4736/60000 (11%)]	 Batch 148 Loss: 0.515054
Train Epoch: 0 Iteration: 150 [4800/60000 (11%)]	 Batch 150 Loss: 1.007353
Train Epoch: 0 Iteration: 152 [4864/60000 (11%)]	 Batch 152 Loss: 0.480062
Train Epoch: 0 Iteration: 154 [4928/60000 (11%)]	 Batch 154 Loss: 0.313867
Train Epoch: 0 Iteration: 156 [4992/60000 (11%)]	 Batch 156 Loss: 0.381373
Train Epoch: 0 Iteration: 158 [5056/60000 (11%)]	 Batch 158 Loss: 0.861435
Train Epoch: 0 Iteration: 160 [5120/60000 (11%)]	 Batch 160 Loss: 0.489843
Train Epoch: 0 Iteration: 162 [5184/60000 (12%)]	 Batch 162 Loss: 0.246711
Train Epoch: 0 Iteration: 164 [5248/60000 (12%)]	 Batch 164 Loss: 0.479186
Train Epoch: 0 Iteration: 166 [5312/60000 (12%)]	 Batch 166 Loss: 0.239268
Train Epoch: 0 Iteration: 168 [5376/60000 (12%)]	 Batch 168 Loss: 0.277616
Train Epoch: 0 Iteration: 170 [5440/60000 (12%)]	 Batch 170 Loss: 0.630378
Train Epoch: 0 Iteration: 172 [5504/60000 (12%)]	 Batch 172 Loss: 0.273236
Train Epoch: 0 Iteration: 174 [5568/60000 (12%)]	 Batch 174 Loss: 0.254982
Train Epoch: 0 Iteration: 176 [5632/60000 (13%)]	 Batch 176 Loss: 0.179665
Train Epoch: 0 Iteration: 178 [5696/60000 (13%)]	 Batch 178 Loss: 0.519286
Train Epoch: 0 Iteration: 180 [5760/60000 (13%)]	 Batch 180 Loss: 0.281409
Train Epoch: 0 Iteration: 182 [5824/60000 (13%)]	 Batch 182 Loss: 0.277705
Train Epoch: 0 Iteration: 184 [5888/60000 (13%)]	 Batch 184 Loss: 0.157214
Train Epoch: 0 Iteration: 186 [5952/60000 (13%)]	 Batch 186 Loss: 0.091547
Train Epoch: 0 Iteration: 188 [6016/60000 (13%)]	 Batch 188 Loss: 0.243710
Train Epoch: 0 Iteration: 190 [6080/60000 (14%)]	 Batch 190 Loss: 0.397698
Train Epoch: 0 Iteration: 192 [6144/60000 (14%)]	 Batch 192 Loss: 0.441480
Train Epoch: 0 Iteration: 194 [6208/60000 (14%)]	 Batch 194 Loss: 0.400277
Train Epoch: 0 Iteration: 196 [6272/60000 (14%)]	 Batch 196 Loss: 0.283215
Train Epoch: 0 Iteration: 198 [6336/60000 (14%)]	 Batch 198 Loss: 0.697221
Train Epoch: 0 Iteration: 200 [6400/60000 (14%)]	 Batch 200 Loss: 0.314237
Train Epoch: 0 Iteration: 202 [6464/60000 (14%)]	 Batch 202 Loss: 0.232603
Train Epoch: 0 Iteration: 204 [6528/60000 (14%)]	 Batch 204 Loss: 0.577090
Train Epoch: 0 Iteration: 206 [6592/60000 (15%)]	 Batch 206 Loss: 0.605177
Train Epoch: 0 Iteration: 208 [6656/60000 (15%)]	 Batch 208 Loss: 0.237527
Train Epoch: 0 Iteration: 210 [6720/60000 (15%)]	 Batch 210 Loss: 0.231505
Train Epoch: 0 Iteration: 212 [6784/60000 (15%)]	 Batch 212 Loss: 0.614103
Train Epoch: 0 Iteration: 214 [6848/60000 (15%)]	 Batch 214 Loss: 0.287317
Train Epoch: 0 Iteration: 216 [6912/60000 (15%)]	 Batch 216 Loss: 0.473040
Train Epoch: 0 Iteration: 218 [6976/60000 (15%)]	 Batch 218 Loss: 0.135453
Train Epoch: 0 Iteration: 220 [7040/60000 (16%)]	 Batch 220 Loss: 0.159720
Train Epoch: 0 Iteration: 222 [7104/60000 (16%)]	 Batch 222 Loss: 0.609395
Train Epoch: 0 Iteration: 224 [7168/60000 (16%)]	 Batch 224 Loss: 0.268651
Train Epoch: 0 Iteration: 226 [7232/60000 (16%)]	 Batch 226 Loss: 0.266476
Train Epoch: 0 Iteration: 228 [7296/60000 (16%)]	 Batch 228 Loss: 0.113057
Train Epoch: 0 Iteration: 230 [7360/60000 (16%)]	 Batch 230 Loss: 0.558365
Train Epoch: 0 Iteration: 232 [7424/60000 (16%)]	 Batch 232 Loss: 0.480735
Train Epoch: 0 Iteration: 234 [7488/60000 (17%)]	 Batch 234 Loss: 0.160428
Train Epoch: 0 Iteration: 236 [7552/60000 (17%)]	 Batch 236 Loss: 0.213883
Train Epoch: 0 Iteration: 238 [7616/60000 (17%)]	 Batch 238 Loss: 0.497013
Train Epoch: 0 Iteration: 240 [7680/60000 (17%)]	 Batch 240 Loss: 0.427118
Train Epoch: 0 Iteration: 242 [7744/60000 (17%)]	 Batch 242 Loss: 0.171618
Train Epoch: 0 Iteration: 244 [7808/60000 (17%)]	 Batch 244 Loss: 0.289809
Train Epoch: 0 Iteration: 246 [7872/60000 (17%)]	 Batch 246 Loss: 0.179086
Train Epoch: 0 Iteration: 248 [7936/60000 (18%)]	 Batch 248 Loss: 0.550156
Train Epoch: 0 Iteration: 250 [8000/60000 (18%)]	 Batch 250 Loss: 0.218920
Train Epoch: 0 Iteration: 252 [8064/60000 (18%)]	 Batch 252 Loss: 0.144013
Train Epoch: 0 Iteration: 254 [8128/60000 (18%)]	 Batch 254 Loss: 0.363059
Train Epoch: 0 Iteration: 256 [8192/60000 (18%)]	 Batch 256 Loss: 0.457483
Train Epoch: 0 Iteration: 258 [8256/60000 (18%)]	 Batch 258 Loss: 0.265627
Train Epoch: 0 Iteration: 260 [8320/60000 (18%)]	 Batch 260 Loss: 0.266153
Train Epoch: 0 Iteration: 262 [8384/60000 (19%)]	 Batch 262 Loss: 0.266917
Train Epoch: 0 Iteration: 264 [8448/60000 (19%)]	 Batch 264 Loss: 0.457665
Train Epoch: 0 Iteration: 266 [8512/60000 (19%)]	 Batch 266 Loss: 0.820630
Train Epoch: 0 Iteration: 268 [8576/60000 (19%)]	 Batch 268 Loss: 0.282485
Train Epoch: 0 Iteration: 270 [8640/60000 (19%)]	 Batch 270 Loss: 0.232163
Train Epoch: 0 Iteration: 272 [8704/60000 (19%)]	 Batch 272 Loss: 0.380641
Train Epoch: 0 Iteration: 274 [8768/60000 (19%)]	 Batch 274 Loss: 0.089239
Train Epoch: 0 Iteration: 276 [8832/60000 (20%)]	 Batch 276 Loss: 0.210453
Train Epoch: 0 Iteration: 278 [8896/60000 (20%)]	 Batch 278 Loss: 0.536730
Train Epoch: 0 Iteration: 280 [8960/60000 (20%)]	 Batch 280 Loss: 0.277940
Train Epoch: 0 Iteration: 282 [9024/60000 (20%)]	 Batch 282 Loss: 0.335861
Train Epoch: 0 Iteration: 284 [9088/60000 (20%)]	 Batch 284 Loss: 0.340518
Train Epoch: 0 Iteration: 286 [9152/60000 (20%)]	 Batch 286 Loss: 0.241864
Train Epoch: 0 Iteration: 288 [9216/60000 (20%)]	 Batch 288 Loss: 0.237874
Train Epoch: 0 Iteration: 290 [9280/60000 (21%)]	 Batch 290 Loss: 0.246819
Train Epoch: 0 Iteration: 292 [9344/60000 (21%)]	 Batch 292 Loss: 0.236097
Train Epoch: 0 Iteration: 294 [9408/60000 (21%)]	 Batch 294 Loss: 0.229373
Train Epoch: 0 Iteration: 296 [9472/60000 (21%)]	 Batch 296 Loss: 0.551121
Train Epoch: 0 Iteration: 298 [9536/60000 (21%)]	 Batch 298 Loss: 0.539761
Train Epoch: 0 Iteration: 300 [9600/60000 (21%)]	 Batch 300 Loss: 0.382400
Train Epoch: 0 Iteration: 302 [9664/60000 (21%)]	 Batch 302 Loss: 0.469692
Train Epoch: 0 Iteration: 304 [9728/60000 (22%)]	 Batch 304 Loss: 0.327183
Train Epoch: 0 Iteration: 306 [9792/60000 (22%)]	 Batch 306 Loss: 0.299115
Train Epoch: 0 Iteration: 308 [9856/60000 (22%)]	 Batch 308 Loss: 0.345074
Train Epoch: 0 Iteration: 310 [9920/60000 (22%)]	 Batch 310 Loss: 0.109903
Train Epoch: 0 Iteration: 312 [9984/60000 (22%)]	 Batch 312 Loss: 0.247149
Train Epoch: 0 Iteration: 314 [10048/60000 (22%)]	 Batch 314 Loss: 0.148891
Train Epoch: 0 Iteration: 316 [10112/60000 (22%)]	 Batch 316 Loss: 0.230824
Train Epoch: 0 Iteration: 318 [10176/60000 (23%)]	 Batch 318 Loss: 0.235193
Train Epoch: 0 Iteration: 320 [10240/60000 (23%)]	 Batch 320 Loss: 0.234242
Train Epoch: 0 Iteration: 322 [10304/60000 (23%)]	 Batch 322 Loss: 0.244191
Train Epoch: 0 Iteration: 324 [10368/60000 (23%)]	 Batch 324 Loss: 0.635294
Train Epoch: 0 Iteration: 326 [10432/60000 (23%)]	 Batch 326 Loss: 0.330556
Train Epoch: 0 Iteration: 328 [10496/60000 (23%)]	 Batch 328 Loss: 0.532866
Train Epoch: 0 Iteration: 330 [10560/60000 (23%)]	 Batch 330 Loss: 0.231780
Train Epoch: 0 Iteration: 332 [10624/60000 (24%)]	 Batch 332 Loss: 0.472377
Train Epoch: 0 Iteration: 334 [10688/60000 (24%)]	 Batch 334 Loss: 0.099721
Train Epoch: 0 Iteration: 336 [10752/60000 (24%)]	 Batch 336 Loss: 0.110740
Train Epoch: 0 Iteration: 338 [10816/60000 (24%)]	 Batch 338 Loss: 0.632559
Train Epoch: 0 Iteration: 340 [10880/60000 (24%)]	 Batch 340 Loss: 0.569066
Train Epoch: 0 Iteration: 342 [10944/60000 (24%)]	 Batch 342 Loss: 0.170813
Train Epoch: 0 Iteration: 344 [11008/60000 (24%)]	 Batch 344 Loss: 0.230206
Train Epoch: 0 Iteration: 346 [11072/60000 (25%)]	 Batch 346 Loss: 0.204904
Train Epoch: 0 Iteration: 348 [11136/60000 (25%)]	 Batch 348 Loss: 0.400105
Train Epoch: 0 Iteration: 350 [11200/60000 (25%)]	 Batch 350 Loss: 0.231315
Train Epoch: 0 Iteration: 352 [11264/60000 (25%)]	 Batch 352 Loss: 0.135983
Train Epoch: 0 Iteration: 354 [11328/60000 (25%)]	 Batch 354 Loss: 0.275109
Train Epoch: 0 Iteration: 356 [11392/60000 (25%)]	 Batch 356 Loss: 0.424490
Train Epoch: 0 Iteration: 358 [11456/60000 (25%)]	 Batch 358 Loss: 0.598656
Train Epoch: 0 Iteration: 360 [11520/60000 (26%)]	 Batch 360 Loss: 0.210545
Train Epoch: 0 Iteration: 362 [11584/60000 (26%)]	 Batch 362 Loss: 0.255899
Train Epoch: 0 Iteration: 364 [11648/60000 (26%)]	 Batch 364 Loss: 0.295200
Train Epoch: 0 Iteration: 366 [11712/60000 (26%)]	 Batch 366 Loss: 0.257890
Train Epoch: 0 Iteration: 368 [11776/60000 (26%)]	 Batch 368 Loss: 0.214690
Train Epoch: 0 Iteration: 370 [11840/60000 (26%)]	 Batch 370 Loss: 0.634999
Train Epoch: 0 Iteration: 372 [11904/60000 (26%)]	 Batch 372 Loss: 0.319433
Train Epoch: 0 Iteration: 374 [11968/60000 (27%)]	 Batch 374 Loss: 0.181334
Train Epoch: 0 Iteration: 376 [12032/60000 (27%)]	 Batch 376 Loss: 0.386126
Train Epoch: 0 Iteration: 378 [12096/60000 (27%)]	 Batch 378 Loss: 0.530449
Train Epoch: 0 Iteration: 380 [12160/60000 (27%)]	 Batch 380 Loss: 0.723583
Train Epoch: 0 Iteration: 382 [12224/60000 (27%)]	 Batch 382 Loss: 0.519249
Train Epoch: 0 Iteration: 384 [12288/60000 (27%)]	 Batch 384 Loss: 0.089831
Train Epoch: 0 Iteration: 386 [12352/60000 (27%)]	 Batch 386 Loss: 0.166052
Train Epoch: 0 Iteration: 388 [12416/60000 (28%)]	 Batch 388 Loss: 0.283659
Train Epoch: 0 Iteration: 390 [12480/60000 (28%)]	 Batch 390 Loss: 0.519696
Train Epoch: 0 Iteration: 392 [12544/60000 (28%)]	 Batch 392 Loss: 0.373355
Train Epoch: 0 Iteration: 394 [12608/60000 (28%)]	 Batch 394 Loss: 0.280666
Train Epoch: 0 Iteration: 396 [12672/60000 (28%)]	 Batch 396 Loss: 0.134254
Train Epoch: 0 Iteration: 398 [12736/60000 (28%)]	 Batch 398 Loss: 0.055362
Train Epoch: 0 Iteration: 400 [12800/60000 (28%)]	 Batch 400 Loss: 0.233822
Train Epoch: 0 Iteration: 402 [12864/60000 (29%)]	 Batch 402 Loss: 0.026961
Train Epoch: 0 Iteration: 404 [12928/60000 (29%)]	 Batch 404 Loss: 0.482808
Train Epoch: 0 Iteration: 406 [12992/60000 (29%)]	 Batch 406 Loss: 0.154380
Train Epoch: 0 Iteration: 408 [13056/60000 (29%)]	 Batch 408 Loss: 0.605883
Train Epoch: 0 Iteration: 410 [13120/60000 (29%)]	 Batch 410 Loss: 0.116078
Train Epoch: 0 Iteration: 412 [13184/60000 (29%)]	 Batch 412 Loss: 0.419523
Train Epoch: 0 Iteration: 414 [13248/60000 (29%)]	 Batch 414 Loss: 0.117210
Train Epoch: 0 Iteration: 416 [13312/60000 (30%)]	 Batch 416 Loss: 0.861162
Train Epoch: 0 Iteration: 418 [13376/60000 (30%)]	 Batch 418 Loss: 0.291165
Train Epoch: 0 Iteration: 420 [13440/60000 (30%)]	 Batch 420 Loss: 0.101174
Train Epoch: 0 Iteration: 422 [13504/60000 (30%)]	 Batch 422 Loss: 0.558987
Train Epoch: 0 Iteration: 424 [13568/60000 (30%)]	 Batch 424 Loss: 0.471060
Train Epoch: 0 Iteration: 426 [13632/60000 (30%)]	 Batch 426 Loss: 0.176293
Train Epoch: 0 Iteration: 428 [13696/60000 (30%)]	 Batch 428 Loss: 0.101951
Train Epoch: 0 Iteration: 430 [13760/60000 (31%)]	 Batch 430 Loss: 0.250096
Train Epoch: 0 Iteration: 432 [13824/60000 (31%)]	 Batch 432 Loss: 0.407911
Train Epoch: 0 Iteration: 434 [13888/60000 (31%)]	 Batch 434 Loss: 0.541181
Train Epoch: 0 Iteration: 436 [13952/60000 (31%)]	 Batch 436 Loss: 0.180705
Train Epoch: 0 Iteration: 438 [14016/60000 (31%)]	 Batch 438 Loss: 0.180186
Train Epoch: 0 Iteration: 440 [14080/60000 (31%)]	 Batch 440 Loss: 0.433329
Train Epoch: 0 Iteration: 442 [14144/60000 (31%)]	 Batch 442 Loss: 0.429111
Train Epoch: 0 Iteration: 444 [14208/60000 (32%)]	 Batch 444 Loss: 0.400370
Train Epoch: 0 Iteration: 446 [14272/60000 (32%)]	 Batch 446 Loss: 0.326571
Train Epoch: 0 Iteration: 448 [14336/60000 (32%)]	 Batch 448 Loss: 0.403744
Train Epoch: 0 Iteration: 450 [14400/60000 (32%)]	 Batch 450 Loss: 0.482934
Train Epoch: 0 Iteration: 452 [14464/60000 (32%)]	 Batch 452 Loss: 0.509122
Train Epoch: 0 Iteration: 454 [14528/60000 (32%)]	 Batch 454 Loss: 0.333723
Train Epoch: 0 Iteration: 456 [14592/60000 (32%)]	 Batch 456 Loss: 0.529765
Train Epoch: 0 Iteration: 458 [14656/60000 (33%)]	 Batch 458 Loss: 0.344939
Train Epoch: 0 Iteration: 460 [14720/60000 (33%)]	 Batch 460 Loss: 0.128116
Train Epoch: 0 Iteration: 462 [14784/60000 (33%)]	 Batch 462 Loss: 0.719196
Train Epoch: 0 Iteration: 464 [14848/60000 (33%)]	 Batch 464 Loss: 0.422410
Train Epoch: 0 Iteration: 466 [14912/60000 (33%)]	 Batch 466 Loss: 0.345069
Train Epoch: 0 Iteration: 468 [14976/60000 (33%)]	 Batch 468 Loss: 0.281240
Train Epoch: 0 Iteration: 470 [15040/60000 (33%)]	 Batch 470 Loss: 0.277100
Train Epoch: 0 Iteration: 472 [15104/60000 (34%)]	 Batch 472 Loss: 0.265555
Train Epoch: 0 Iteration: 474 [15168/60000 (34%)]	 Batch 474 Loss: 0.160455
Train Epoch: 0 Iteration: 476 [15232/60000 (34%)]	 Batch 476 Loss: 0.412559
Train Epoch: 0 Iteration: 478 [15296/60000 (34%)]	 Batch 478 Loss: 0.123031
Train Epoch: 0 Iteration: 480 [15360/60000 (34%)]	 Batch 480 Loss: 0.445704
Train Epoch: 0 Iteration: 482 [15424/60000 (34%)]	 Batch 482 Loss: 0.205846
Train Epoch: 0 Iteration: 484 [15488/60000 (34%)]	 Batch 484 Loss: 0.200881
Train Epoch: 0 Iteration: 486 [15552/60000 (35%)]	 Batch 486 Loss: 0.169237
Train Epoch: 0 Iteration: 488 [15616/60000 (35%)]	 Batch 488 Loss: 0.368567
Train Epoch: 0 Iteration: 490 [15680/60000 (35%)]	 Batch 490 Loss: 0.218773
Train Epoch: 0 Iteration: 492 [15744/60000 (35%)]	 Batch 492 Loss: 0.257306
Train Epoch: 0 Iteration: 494 [15808/60000 (35%)]	 Batch 494 Loss: 0.142614
Train Epoch: 0 Iteration: 496 [15872/60000 (35%)]	 Batch 496 Loss: 0.451904
Train Epoch: 0 Iteration: 498 [15936/60000 (35%)]	 Batch 498 Loss: 0.422422
Train Epoch: 0 Iteration: 500 [16000/60000 (36%)]	 Batch 500 Loss: 0.350424
Train Epoch: 0 Iteration: 502 [16064/60000 (36%)]	 Batch 502 Loss: 0.057361
Train Epoch: 0 Iteration: 504 [16128/60000 (36%)]	 Batch 504 Loss: 0.312572
Train Epoch: 0 Iteration: 506 [16192/60000 (36%)]	 Batch 506 Loss: 0.185210
Train Epoch: 0 Iteration: 508 [16256/60000 (36%)]	 Batch 508 Loss: 0.293687
Train Epoch: 0 Iteration: 510 [16320/60000 (36%)]	 Batch 510 Loss: 0.203060
Train Epoch: 0 Iteration: 512 [16384/60000 (36%)]	 Batch 512 Loss: 0.299986
Train Epoch: 0 Iteration: 514 [16448/60000 (37%)]	 Batch 514 Loss: 0.275868
Train Epoch: 0 Iteration: 516 [16512/60000 (37%)]	 Batch 516 Loss: 0.099471
Train Epoch: 0 Iteration: 518 [16576/60000 (37%)]	 Batch 518 Loss: 0.129980
Train Epoch: 0 Iteration: 520 [16640/60000 (37%)]	 Batch 520 Loss: 0.238777
Train Epoch: 0 Iteration: 522 [16704/60000 (37%)]	 Batch 522 Loss: 0.194061
Train Epoch: 0 Iteration: 524 [16768/60000 (37%)]	 Batch 524 Loss: 0.342411
Train Epoch: 0 Iteration: 526 [16832/60000 (37%)]	 Batch 526 Loss: 0.337219
Train Epoch: 0 Iteration: 528 [16896/60000 (38%)]	 Batch 528 Loss: 0.213997
Train Epoch: 0 Iteration: 530 [16960/60000 (38%)]	 Batch 530 Loss: 0.350649
Train Epoch: 0 Iteration: 532 [17024/60000 (38%)]	 Batch 532 Loss: 0.167108
Train Epoch: 0 Iteration: 534 [17088/60000 (38%)]	 Batch 534 Loss: 0.164981
Train Epoch: 0 Iteration: 536 [17152/60000 (38%)]	 Batch 536 Loss: 0.405678
Train Epoch: 0 Iteration: 538 [17216/60000 (38%)]	 Batch 538 Loss: 0.515475
Train Epoch: 0 Iteration: 540 [17280/60000 (38%)]	 Batch 540 Loss: 0.561093
Train Epoch: 0 Iteration: 542 [17344/60000 (39%)]	 Batch 542 Loss: 0.389665
Train Epoch: 0 Iteration: 544 [17408/60000 (39%)]	 Batch 544 Loss: 0.480702
Train Epoch: 0 Iteration: 546 [17472/60000 (39%)]	 Batch 546 Loss: 0.088277
Train Epoch: 0 Iteration: 548 [17536/60000 (39%)]	 Batch 548 Loss: 0.267416
Train Epoch: 0 Iteration: 550 [17600/60000 (39%)]	 Batch 550 Loss: 0.517480
Train Epoch: 0 Iteration: 552 [17664/60000 (39%)]	 Batch 552 Loss: 0.157665
Train Epoch: 0 Iteration: 554 [17728/60000 (39%)]	 Batch 554 Loss: 0.110859
Train Epoch: 0 Iteration: 556 [17792/60000 (40%)]	 Batch 556 Loss: 0.412228
Train Epoch: 0 Iteration: 558 [17856/60000 (40%)]	 Batch 558 Loss: 0.238530
Train Epoch: 0 Iteration: 560 [17920/60000 (40%)]	 Batch 560 Loss: 0.271862
Train Epoch: 0 Iteration: 562 [17984/60000 (40%)]	 Batch 562 Loss: 0.184085
Train Epoch: 0 Iteration: 564 [18048/60000 (40%)]	 Batch 564 Loss: 0.067551
Train Epoch: 0 Iteration: 566 [18112/60000 (40%)]	 Batch 566 Loss: 0.231797
Train Epoch: 0 Iteration: 568 [18176/60000 (40%)]	 Batch 568 Loss: 0.186606
Train Epoch: 0 Iteration: 570 [18240/60000 (41%)]	 Batch 570 Loss: 0.579554
Train Epoch: 0 Iteration: 572 [18304/60000 (41%)]	 Batch 572 Loss: 0.160736
Train Epoch: 0 Iteration: 574 [18368/60000 (41%)]	 Batch 574 Loss: 0.347348
Train Epoch: 0 Iteration: 576 [18432/60000 (41%)]	 Batch 576 Loss: 0.666533
Train Epoch: 0 Iteration: 578 [18496/60000 (41%)]	 Batch 578 Loss: 0.393072
Train Epoch: 0 Iteration: 580 [18560/60000 (41%)]	 Batch 580 Loss: 0.317181
Train Epoch: 0 Iteration: 582 [18624/60000 (41%)]	 Batch 582 Loss: 0.236669
Train Epoch: 0 Iteration: 584 [18688/60000 (42%)]	 Batch 584 Loss: 0.302816
Train Epoch: 0 Iteration: 586 [18752/60000 (42%)]	 Batch 586 Loss: 0.515905
Train Epoch: 0 Iteration: 588 [18816/60000 (42%)]	 Batch 588 Loss: 0.500274
Train Epoch: 0 Iteration: 590 [18880/60000 (42%)]	 Batch 590 Loss: 0.890222
Train Epoch: 0 Iteration: 592 [18944/60000 (42%)]	 Batch 592 Loss: 0.386202
Train Epoch: 0 Iteration: 594 [19008/60000 (42%)]	 Batch 594 Loss: 0.134577
Train Epoch: 0 Iteration: 596 [19072/60000 (42%)]	 Batch 596 Loss: 0.303566
Train Epoch: 0 Iteration: 598 [19136/60000 (43%)]	 Batch 598 Loss: 0.104623
Train Epoch: 0 Iteration: 600 [19200/60000 (43%)]	 Batch 600 Loss: 0.246464
Train Epoch: 0 Iteration: 602 [19264/60000 (43%)]	 Batch 602 Loss: 0.547705
Train Epoch: 0 Iteration: 604 [19328/60000 (43%)]	 Batch 604 Loss: 0.099596
Train Epoch: 0 Iteration: 606 [19392/60000 (43%)]	 Batch 606 Loss: 0.195614
Train Epoch: 0 Iteration: 608 [19456/60000 (43%)]	 Batch 608 Loss: 0.601011
Train Epoch: 0 Iteration: 610 [19520/60000 (43%)]	 Batch 610 Loss: 0.154168
Train Epoch: 0 Iteration: 612 [19584/60000 (43%)]	 Batch 612 Loss: 0.118991
Train Epoch: 0 Iteration: 614 [19648/60000 (44%)]	 Batch 614 Loss: 0.196468
Train Epoch: 0 Iteration: 616 [19712/60000 (44%)]	 Batch 616 Loss: 0.467153
Train Epoch: 0 Iteration: 618 [19776/60000 (44%)]	 Batch 618 Loss: 0.413023
Train Epoch: 0 Iteration: 620 [19840/60000 (44%)]	 Batch 620 Loss: 0.643458
Train Epoch: 0 Iteration: 622 [19904/60000 (44%)]	 Batch 622 Loss: 0.251061
Train Epoch: 0 Iteration: 624 [19968/60000 (44%)]	 Batch 624 Loss: 0.164760
Train Epoch: 0 Iteration: 626 [20032/60000 (44%)]	 Batch 626 Loss: 0.067068
Train Epoch: 0 Iteration: 628 [20096/60000 (45%)]	 Batch 628 Loss: 0.249991
Train Epoch: 0 Iteration: 630 [20160/60000 (45%)]	 Batch 630 Loss: 0.118053
Train Epoch: 0 Iteration: 632 [20224/60000 (45%)]	 Batch 632 Loss: 0.260290
Train Epoch: 0 Iteration: 634 [20288/60000 (45%)]	 Batch 634 Loss: 0.680998
Train Epoch: 0 Iteration: 636 [20352/60000 (45%)]	 Batch 636 Loss: 0.201535
Train Epoch: 0 Iteration: 638 [20416/60000 (45%)]	 Batch 638 Loss: 0.340856
Train Epoch: 0 Iteration: 640 [20480/60000 (45%)]	 Batch 640 Loss: 0.152933
Train Epoch: 0 Iteration: 642 [20544/60000 (46%)]	 Batch 642 Loss: 0.372880
Train Epoch: 0 Iteration: 644 [20608/60000 (46%)]	 Batch 644 Loss: 0.182550
Train Epoch: 0 Iteration: 646 [20672/60000 (46%)]	 Batch 646 Loss: 0.300343
Train Epoch: 0 Iteration: 648 [20736/60000 (46%)]	 Batch 648 Loss: 0.566162
Train Epoch: 0 Iteration: 650 [20800/60000 (46%)]	 Batch 650 Loss: 0.214874
Train Epoch: 0 Iteration: 652 [20864/60000 (46%)]	 Batch 652 Loss: 0.154475
Train Epoch: 0 Iteration: 654 [20928/60000 (46%)]	 Batch 654 Loss: 0.109894
Train Epoch: 0 Iteration: 656 [20992/60000 (47%)]	 Batch 656 Loss: 0.425595
Train Epoch: 0 Iteration: 658 [21056/60000 (47%)]	 Batch 658 Loss: 0.191539
Train Epoch: 0 Iteration: 660 [21120/60000 (47%)]	 Batch 660 Loss: 0.502435
Train Epoch: 0 Iteration: 662 [21184/60000 (47%)]	 Batch 662 Loss: 0.165193
Train Epoch: 0 Iteration: 664 [21248/60000 (47%)]	 Batch 664 Loss: 0.341383
Train Epoch: 0 Iteration: 666 [21312/60000 (47%)]	 Batch 666 Loss: 0.580774
Train Epoch: 0 Iteration: 668 [21376/60000 (47%)]	 Batch 668 Loss: 0.052283
Train Epoch: 0 Iteration: 670 [21440/60000 (48%)]	 Batch 670 Loss: 0.336977
Train Epoch: 0 Iteration: 672 [21504/60000 (48%)]	 Batch 672 Loss: 0.207666
Train Epoch: 0 Iteration: 674 [21568/60000 (48%)]	 Batch 674 Loss: 0.043262
Train Epoch: 0 Iteration: 676 [21632/60000 (48%)]	 Batch 676 Loss: 0.146801
Train Epoch: 0 Iteration: 678 [21696/60000 (48%)]	 Batch 678 Loss: 0.293225
Train Epoch: 0 Iteration: 680 [21760/60000 (48%)]	 Batch 680 Loss: 0.322018
Train Epoch: 0 Iteration: 682 [21824/60000 (48%)]	 Batch 682 Loss: 0.492582
Train Epoch: 0 Iteration: 684 [21888/60000 (49%)]	 Batch 684 Loss: 0.108484
Train Epoch: 0 Iteration: 686 [21952/60000 (49%)]	 Batch 686 Loss: 0.320670
Train Epoch: 0 Iteration: 688 [22016/60000 (49%)]	 Batch 688 Loss: 0.256567
Train Epoch: 0 Iteration: 690 [22080/60000 (49%)]	 Batch 690 Loss: 0.493266
Train Epoch: 0 Iteration: 692 [22144/60000 (49%)]	 Batch 692 Loss: 0.462690
Train Epoch: 0 Iteration: 694 [22208/60000 (49%)]	 Batch 694 Loss: 0.190516
Train Epoch: 0 Iteration: 696 [22272/60000 (49%)]	 Batch 696 Loss: 0.223459
Train Epoch: 0 Iteration: 698 [22336/60000 (50%)]	 Batch 698 Loss: 0.207487
Train Epoch: 0 Iteration: 700 [22400/60000 (50%)]	 Batch 700 Loss: 0.426589
Train Epoch: 0 Iteration: 702 [22464/60000 (50%)]	 Batch 702 Loss: 0.250530
Train Epoch: 0 Iteration: 704 [22528/60000 (50%)]	 Batch 704 Loss: 0.135608
Train Epoch: 0 Iteration: 706 [22592/60000 (50%)]	 Batch 706 Loss: 0.240879
Train Epoch: 0 Iteration: 708 [22656/60000 (50%)]	 Batch 708 Loss: 0.096801
Train Epoch: 0 Iteration: 710 [22720/60000 (50%)]	 Batch 710 Loss: 0.216739
Train Epoch: 0 Iteration: 712 [22784/60000 (51%)]	 Batch 712 Loss: 0.155053
Train Epoch: 0 Iteration: 714 [22848/60000 (51%)]	 Batch 714 Loss: 0.268346
Train Epoch: 0 Iteration: 716 [22912/60000 (51%)]	 Batch 716 Loss: 0.196360
Train Epoch: 0 Iteration: 718 [22976/60000 (51%)]	 Batch 718 Loss: 0.327411
Train Epoch: 0 Iteration: 720 [23040/60000 (51%)]	 Batch 720 Loss: 0.287196
Train Epoch: 0 Iteration: 722 [23104/60000 (51%)]	 Batch 722 Loss: 0.426940
Train Epoch: 0 Iteration: 724 [23168/60000 (51%)]	 Batch 724 Loss: 0.113245
Train Epoch: 0 Iteration: 726 [23232/60000 (52%)]	 Batch 726 Loss: 0.334143
Train Epoch: 0 Iteration: 728 [23296/60000 (52%)]	 Batch 728 Loss: 0.248923
Train Epoch: 0 Iteration: 730 [23360/60000 (52%)]	 Batch 730 Loss: 0.856232
Train Epoch: 0 Iteration: 732 [23424/60000 (52%)]	 Batch 732 Loss: 0.178906
Train Epoch: 0 Iteration: 734 [23488/60000 (52%)]	 Batch 734 Loss: 0.328801
Train Epoch: 0 Iteration: 736 [23552/60000 (52%)]	 Batch 736 Loss: 0.444777
Train Epoch: 0 Iteration: 738 [23616/60000 (52%)]	 Batch 738 Loss: 0.281630
Train Epoch: 0 Iteration: 740 [23680/60000 (53%)]	 Batch 740 Loss: 0.128518
Train Epoch: 0 Iteration: 742 [23744/60000 (53%)]	 Batch 742 Loss: 0.368991
Train Epoch: 0 Iteration: 744 [23808/60000 (53%)]	 Batch 744 Loss: 0.465436
Train Epoch: 0 Iteration: 746 [23872/60000 (53%)]	 Batch 746 Loss: 0.517609
Train Epoch: 0 Iteration: 748 [23936/60000 (53%)]	 Batch 748 Loss: 0.279015
Train Epoch: 0 Iteration: 750 [24000/60000 (53%)]	 Batch 750 Loss: 0.207493
Train Epoch: 0 Iteration: 752 [24064/60000 (53%)]	 Batch 752 Loss: 0.074669
Train Epoch: 0 Iteration: 754 [24128/60000 (54%)]	 Batch 754 Loss: 0.065636
Train Epoch: 0 Iteration: 756 [24192/60000 (54%)]	 Batch 756 Loss: 0.093927
Train Epoch: 0 Iteration: 758 [24256/60000 (54%)]	 Batch 758 Loss: 0.611844
Train Epoch: 0 Iteration: 760 [24320/60000 (54%)]	 Batch 760 Loss: 0.418756
Train Epoch: 0 Iteration: 762 [24384/60000 (54%)]	 Batch 762 Loss: 0.238801
Train Epoch: 0 Iteration: 764 [24448/60000 (54%)]	 Batch 764 Loss: 0.055887
Train Epoch: 0 Iteration: 766 [24512/60000 (54%)]	 Batch 766 Loss: 0.182192
Train Epoch: 0 Iteration: 768 [24576/60000 (55%)]	 Batch 768 Loss: 0.406746
Train Epoch: 0 Iteration: 770 [24640/60000 (55%)]	 Batch 770 Loss: 0.138567
Train Epoch: 0 Iteration: 772 [24704/60000 (55%)]	 Batch 772 Loss: 0.337844
Train Epoch: 0 Iteration: 774 [24768/60000 (55%)]	 Batch 774 Loss: 0.186173
Train Epoch: 0 Iteration: 776 [24832/60000 (55%)]	 Batch 776 Loss: 0.311616
Train Epoch: 0 Iteration: 778 [24896/60000 (55%)]	 Batch 778 Loss: 0.358648
Train Epoch: 0 Iteration: 780 [24960/60000 (55%)]	 Batch 780 Loss: 0.464166
Train Epoch: 0 Iteration: 782 [25024/60000 (56%)]	 Batch 782 Loss: 0.174512
Train Epoch: 0 Iteration: 784 [25088/60000 (56%)]	 Batch 784 Loss: 0.396334
Train Epoch: 0 Iteration: 786 [25152/60000 (56%)]	 Batch 786 Loss: 0.234136
Train Epoch: 0 Iteration: 788 [25216/60000 (56%)]	 Batch 788 Loss: 0.172363
Train Epoch: 0 Iteration: 790 [25280/60000 (56%)]	 Batch 790 Loss: 0.205609
Train Epoch: 0 Iteration: 792 [25344/60000 (56%)]	 Batch 792 Loss: 0.324456
Train Epoch: 0 Iteration: 794 [25408/60000 (56%)]	 Batch 794 Loss: 0.252191
Train Epoch: 0 Iteration: 796 [25472/60000 (57%)]	 Batch 796 Loss: 0.248627
Train Epoch: 0 Iteration: 798 [25536/60000 (57%)]	 Batch 798 Loss: 0.741493
Train Epoch: 0 Iteration: 800 [25600/60000 (57%)]	 Batch 800 Loss: 0.334000
Train Epoch: 0 Iteration: 802 [25664/60000 (57%)]	 Batch 802 Loss: 0.193838
Train Epoch: 0 Iteration: 804 [25728/60000 (57%)]	 Batch 804 Loss: 0.365052
Train Epoch: 0 Iteration: 806 [25792/60000 (57%)]	 Batch 806 Loss: 0.412149
Train Epoch: 0 Iteration: 808 [25856/60000 (57%)]	 Batch 808 Loss: 0.302158
Train Epoch: 0 Iteration: 810 [25920/60000 (58%)]	 Batch 810 Loss: 0.267608
Train Epoch: 0 Iteration: 812 [25984/60000 (58%)]	 Batch 812 Loss: 0.392990
Train Epoch: 0 Iteration: 814 [26048/60000 (58%)]	 Batch 814 Loss: 0.396660
Train Epoch: 0 Iteration: 816 [26112/60000 (58%)]	 Batch 816 Loss: 0.292818
Train Epoch: 0 Iteration: 818 [26176/60000 (58%)]	 Batch 818 Loss: 0.134353
Train Epoch: 0 Iteration: 820 [26240/60000 (58%)]	 Batch 820 Loss: 0.415372
Train Epoch: 0 Iteration: 822 [26304/60000 (58%)]	 Batch 822 Loss: 0.198819
Train Epoch: 0 Iteration: 824 [26368/60000 (59%)]	 Batch 824 Loss: 0.540241
Train Epoch: 0 Iteration: 826 [26432/60000 (59%)]	 Batch 826 Loss: 0.432245
Train Epoch: 0 Iteration: 828 [26496/60000 (59%)]	 Batch 828 Loss: 0.508320
Train Epoch: 0 Iteration: 830 [26560/60000 (59%)]	 Batch 830 Loss: 0.183224
Train Epoch: 0 Iteration: 832 [26624/60000 (59%)]	 Batch 832 Loss: 0.435720
Train Epoch: 0 Iteration: 834 [26688/60000 (59%)]	 Batch 834 Loss: 0.368639
Train Epoch: 0 Iteration: 836 [26752/60000 (59%)]	 Batch 836 Loss: 0.261058
Train Epoch: 0 Iteration: 838 [26816/60000 (60%)]	 Batch 838 Loss: 0.159620
Train Epoch: 0 Iteration: 840 [26880/60000 (60%)]	 Batch 840 Loss: 0.038228
Train Epoch: 0 Iteration: 842 [26944/60000 (60%)]	 Batch 842 Loss: 0.344609
Train Epoch: 0 Iteration: 844 [27008/60000 (60%)]	 Batch 844 Loss: 0.077359
Train Epoch: 0 Iteration: 846 [27072/60000 (60%)]	 Batch 846 Loss: 0.482048
Train Epoch: 0 Iteration: 848 [27136/60000 (60%)]	 Batch 848 Loss: 0.201337
Train Epoch: 0 Iteration: 850 [27200/60000 (60%)]	 Batch 850 Loss: 0.233707
Train Epoch: 0 Iteration: 852 [27264/60000 (61%)]	 Batch 852 Loss: 0.197201
Train Epoch: 0 Iteration: 854 [27328/60000 (61%)]	 Batch 854 Loss: 0.215350
Train Epoch: 0 Iteration: 856 [27392/60000 (61%)]	 Batch 856 Loss: 0.271904
Train Epoch: 0 Iteration: 858 [27456/60000 (61%)]	 Batch 858 Loss: 0.378497
Train Epoch: 0 Iteration: 860 [27520/60000 (61%)]	 Batch 860 Loss: 0.094582
Train Epoch: 0 Iteration: 862 [27584/60000 (61%)]	 Batch 862 Loss: 0.255621
Train Epoch: 0 Iteration: 864 [27648/60000 (61%)]	 Batch 864 Loss: 0.140797
Train Epoch: 0 Iteration: 866 [27712/60000 (62%)]	 Batch 866 Loss: 0.326419
Train Epoch: 0 Iteration: 868 [27776/60000 (62%)]	 Batch 868 Loss: 0.277346
Train Epoch: 0 Iteration: 870 [27840/60000 (62%)]	 Batch 870 Loss: 0.135817
Train Epoch: 0 Iteration: 872 [27904/60000 (62%)]	 Batch 872 Loss: 0.492666
Train Epoch: 0 Iteration: 874 [27968/60000 (62%)]	 Batch 874 Loss: 0.364085
Train Epoch: 0 Iteration: 876 [28032/60000 (62%)]	 Batch 876 Loss: 0.512694
Train Epoch: 0 Iteration: 878 [28096/60000 (62%)]	 Batch 878 Loss: 0.234948
Train Epoch: 0 Iteration: 880 [28160/60000 (63%)]	 Batch 880 Loss: 0.067610
Train Epoch: 0 Iteration: 882 [28224/60000 (63%)]	 Batch 882 Loss: 0.042619
Train Epoch: 0 Iteration: 884 [28288/60000 (63%)]	 Batch 884 Loss: 0.161093
Train Epoch: 0 Iteration: 886 [28352/60000 (63%)]	 Batch 886 Loss: 0.258816
Train Epoch: 0 Iteration: 888 [28416/60000 (63%)]	 Batch 888 Loss: 0.388291
Train Epoch: 0 Iteration: 890 [28480/60000 (63%)]	 Batch 890 Loss: 0.118526
Train Epoch: 0 Iteration: 892 [28544/60000 (63%)]	 Batch 892 Loss: 0.258129
Train Epoch: 0 Iteration: 894 [28608/60000 (64%)]	 Batch 894 Loss: 0.104143
Train Epoch: 0 Iteration: 896 [28672/60000 (64%)]	 Batch 896 Loss: 0.193116
Train Epoch: 0 Iteration: 898 [28736/60000 (64%)]	 Batch 898 Loss: 0.138720
Train Epoch: 0 Iteration: 900 [28800/60000 (64%)]	 Batch 900 Loss: 0.239596
Train Epoch: 0 Iteration: 902 [28864/60000 (64%)]	 Batch 902 Loss: 0.039408
Train Epoch: 0 Iteration: 904 [28928/60000 (64%)]	 Batch 904 Loss: 0.146030
Train Epoch: 0 Iteration: 906 [28992/60000 (64%)]	 Batch 906 Loss: 0.249467
Train Epoch: 0 Iteration: 908 [29056/60000 (65%)]	 Batch 908 Loss: 0.240273
Train Epoch: 0 Iteration: 910 [29120/60000 (65%)]	 Batch 910 Loss: 0.323621
Train Epoch: 0 Iteration: 912 [29184/60000 (65%)]	 Batch 912 Loss: 0.210734
Train Epoch: 0 Iteration: 914 [29248/60000 (65%)]	 Batch 914 Loss: 0.073498
Train Epoch: 0 Iteration: 916 [29312/60000 (65%)]	 Batch 916 Loss: 0.135902
Train Epoch: 0 Iteration: 918 [29376/60000 (65%)]	 Batch 918 Loss: 0.186367
Train Epoch: 0 Iteration: 920 [29440/60000 (65%)]	 Batch 920 Loss: 0.433488
Train Epoch: 0 Iteration: 922 [29504/60000 (66%)]	 Batch 922 Loss: 0.422454
Train Epoch: 0 Iteration: 924 [29568/60000 (66%)]	 Batch 924 Loss: 0.165255
Train Epoch: 0 Iteration: 926 [29632/60000 (66%)]	 Batch 926 Loss: 0.091167
Train Epoch: 0 Iteration: 928 [29696/60000 (66%)]	 Batch 928 Loss: 0.246094
Train Epoch: 0 Iteration: 930 [29760/60000 (66%)]	 Batch 930 Loss: 0.321168
Train Epoch: 0 Iteration: 932 [29824/60000 (66%)]	 Batch 932 Loss: 0.146072
Train Epoch: 0 Iteration: 934 [29888/60000 (66%)]	 Batch 934 Loss: 0.184845
Train Epoch: 0 Iteration: 936 [29952/60000 (67%)]	 Batch 936 Loss: 0.385655
Train Epoch: 0 Iteration: 938 [30016/60000 (67%)]	 Batch 938 Loss: 0.199183
Train Epoch: 0 Iteration: 940 [30080/60000 (67%)]	 Batch 940 Loss: 0.221460
Train Epoch: 0 Iteration: 942 [30144/60000 (67%)]	 Batch 942 Loss: 0.080737
Train Epoch: 0 Iteration: 944 [30208/60000 (67%)]	 Batch 944 Loss: 0.128169
Train Epoch: 0 Iteration: 946 [30272/60000 (67%)]	 Batch 946 Loss: 0.066805
Train Epoch: 0 Iteration: 948 [30336/60000 (67%)]	 Batch 948 Loss: 0.280405
Train Epoch: 0 Iteration: 950 [30400/60000 (68%)]	 Batch 950 Loss: 0.334634
Train Epoch: 0 Iteration: 952 [30464/60000 (68%)]	 Batch 952 Loss: 0.127185
Train Epoch: 0 Iteration: 954 [30528/60000 (68%)]	 Batch 954 Loss: 0.275017
Train Epoch: 0 Iteration: 956 [30592/60000 (68%)]	 Batch 956 Loss: 0.518369
Train Epoch: 0 Iteration: 958 [30656/60000 (68%)]	 Batch 958 Loss: 0.488291
Train Epoch: 0 Iteration: 960 [30720/60000 (68%)]	 Batch 960 Loss: 0.249714
Train Epoch: 0 Iteration: 962 [30784/60000 (68%)]	 Batch 962 Loss: 0.282999
Train Epoch: 0 Iteration: 964 [30848/60000 (69%)]	 Batch 964 Loss: 0.054554
Train Epoch: 0 Iteration: 966 [30912/60000 (69%)]	 Batch 966 Loss: 0.229075
Train Epoch: 0 Iteration: 968 [30976/60000 (69%)]	 Batch 968 Loss: 0.413379
Train Epoch: 0 Iteration: 970 [31040/60000 (69%)]	 Batch 970 Loss: 0.034663
Train Epoch: 0 Iteration: 972 [31104/60000 (69%)]	 Batch 972 Loss: 0.382164
Train Epoch: 0 Iteration: 974 [31168/60000 (69%)]	 Batch 974 Loss: 0.407469
Train Epoch: 0 Iteration: 976 [31232/60000 (69%)]	 Batch 976 Loss: 0.666159
Train Epoch: 0 Iteration: 978 [31296/60000 (70%)]	 Batch 978 Loss: 0.381583
Train Epoch: 0 Iteration: 980 [31360/60000 (70%)]	 Batch 980 Loss: 0.147484
Train Epoch: 0 Iteration: 982 [31424/60000 (70%)]	 Batch 982 Loss: 0.220461
Train Epoch: 0 Iteration: 984 [31488/60000 (70%)]	 Batch 984 Loss: 0.268888
Train Epoch: 0 Iteration: 986 [31552/60000 (70%)]	 Batch 986 Loss: 0.177787
Train Epoch: 0 Iteration: 988 [31616/60000 (70%)]	 Batch 988 Loss: 0.076641
Train Epoch: 0 Iteration: 990 [31680/60000 (70%)]	 Batch 990 Loss: 0.291169
Train Epoch: 0 Iteration: 992 [31744/60000 (71%)]	 Batch 992 Loss: 0.282262
Train Epoch: 0 Iteration: 994 [31808/60000 (71%)]	 Batch 994 Loss: 0.183434
Train Epoch: 0 Iteration: 996 [31872/60000 (71%)]	 Batch 996 Loss: 0.097639
Train Epoch: 0 Iteration: 998 [31936/60000 (71%)]	 Batch 998 Loss: 0.369511
Train Epoch: 0 Iteration: 1000 [32000/60000 (71%)]	 Batch 1000 Loss: 0.171692
Train Epoch: 0 Iteration: 1002 [32064/60000 (71%)]	 Batch 1002 Loss: 0.347874
Train Epoch: 0 Iteration: 1004 [32128/60000 (71%)]	 Batch 1004 Loss: 0.269350
Train Epoch: 0 Iteration: 1006 [32192/60000 (71%)]	 Batch 1006 Loss: 0.085398
Train Epoch: 0 Iteration: 1008 [32256/60000 (72%)]	 Batch 1008 Loss: 0.091954
Train Epoch: 0 Iteration: 1010 [32320/60000 (72%)]	 Batch 1010 Loss: 0.127174
Train Epoch: 0 Iteration: 1012 [32384/60000 (72%)]	 Batch 1012 Loss: 0.386899
Train Epoch: 0 Iteration: 1014 [32448/60000 (72%)]	 Batch 1014 Loss: 0.238865
Train Epoch: 0 Iteration: 1016 [32512/60000 (72%)]	 Batch 1016 Loss: 0.524045
Train Epoch: 0 Iteration: 1018 [32576/60000 (72%)]	 Batch 1018 Loss: 0.403486
Train Epoch: 0 Iteration: 1020 [32640/60000 (72%)]	 Batch 1020 Loss: 0.259654
Train Epoch: 0 Iteration: 1022 [32704/60000 (73%)]	 Batch 1022 Loss: 0.694004
Train Epoch: 0 Iteration: 1024 [32768/60000 (73%)]	 Batch 1024 Loss: 0.193715
Train Epoch: 0 Iteration: 1026 [32832/60000 (73%)]	 Batch 1026 Loss: 0.315986
Train Epoch: 0 Iteration: 1028 [32896/60000 (73%)]	 Batch 1028 Loss: 0.194467
Train Epoch: 0 Iteration: 1030 [32960/60000 (73%)]	 Batch 1030 Loss: 0.440593
Train Epoch: 0 Iteration: 1032 [33024/60000 (73%)]	 Batch 1032 Loss: 0.040167
Train Epoch: 0 Iteration: 1034 [33088/60000 (73%)]	 Batch 1034 Loss: 0.086915
Train Epoch: 0 Iteration: 1036 [33152/60000 (74%)]	 Batch 1036 Loss: 0.288432
Train Epoch: 0 Iteration: 1038 [33216/60000 (74%)]	 Batch 1038 Loss: 0.391544
Train Epoch: 0 Iteration: 1040 [33280/60000 (74%)]	 Batch 1040 Loss: 0.274928
Train Epoch: 0 Iteration: 1042 [33344/60000 (74%)]	 Batch 1042 Loss: 0.263084
Train Epoch: 0 Iteration: 1044 [33408/60000 (74%)]	 Batch 1044 Loss: 0.085180
Train Epoch: 0 Iteration: 1046 [33472/60000 (74%)]	 Batch 1046 Loss: 0.414931
Train Epoch: 0 Iteration: 1048 [33536/60000 (74%)]	 Batch 1048 Loss: 0.320296
Train Epoch: 0 Iteration: 1050 [33600/60000 (75%)]	 Batch 1050 Loss: 0.330976
Train Epoch: 0 Iteration: 1052 [33664/60000 (75%)]	 Batch 1052 Loss: 0.195764
Train Epoch: 0 Iteration: 1054 [33728/60000 (75%)]	 Batch 1054 Loss: 0.119948
Train Epoch: 0 Iteration: 1056 [33792/60000 (75%)]	 Batch 1056 Loss: 0.172224
Train Epoch: 0 Iteration: 1058 [33856/60000 (75%)]	 Batch 1058 Loss: 0.272898
Train Epoch: 0 Iteration: 1060 [33920/60000 (75%)]	 Batch 1060 Loss: 0.139223
Train Epoch: 0 Iteration: 1062 [33984/60000 (75%)]	 Batch 1062 Loss: 0.192123
Train Epoch: 0 Iteration: 1064 [34048/60000 (76%)]	 Batch 1064 Loss: 0.338099
Train Epoch: 0 Iteration: 1066 [34112/60000 (76%)]	 Batch 1066 Loss: 0.161378
Train Epoch: 0 Iteration: 1068 [34176/60000 (76%)]	 Batch 1068 Loss: 0.409283
Train Epoch: 0 Iteration: 1070 [34240/60000 (76%)]	 Batch 1070 Loss: 0.198445
Train Epoch: 0 Iteration: 1072 [34304/60000 (76%)]	 Batch 1072 Loss: 0.151536
Train Epoch: 0 Iteration: 1074 [34368/60000 (76%)]	 Batch 1074 Loss: 0.064553
Train Epoch: 0 Iteration: 1076 [34432/60000 (76%)]	 Batch 1076 Loss: 0.569625
Train Epoch: 0 Iteration: 1078 [34496/60000 (77%)]	 Batch 1078 Loss: 0.289983
Train Epoch: 0 Iteration: 1080 [34560/60000 (77%)]	 Batch 1080 Loss: 0.065756
Train Epoch: 0 Iteration: 1082 [34624/60000 (77%)]	 Batch 1082 Loss: 0.088401
Train Epoch: 0 Iteration: 1084 [34688/60000 (77%)]	 Batch 1084 Loss: 0.208763
Train Epoch: 0 Iteration: 1086 [34752/60000 (77%)]	 Batch 1086 Loss: 0.057965
Train Epoch: 0 Iteration: 1088 [34816/60000 (77%)]	 Batch 1088 Loss: 0.162761
Train Epoch: 0 Iteration: 1090 [34880/60000 (77%)]	 Batch 1090 Loss: 0.747597
Train Epoch: 0 Iteration: 1092 [34944/60000 (78%)]	 Batch 1092 Loss: 0.357236
Train Epoch: 0 Iteration: 1094 [35008/60000 (78%)]	 Batch 1094 Loss: 0.197029
Train Epoch: 0 Iteration: 1096 [35072/60000 (78%)]	 Batch 1096 Loss: 0.114359
Train Epoch: 0 Iteration: 1098 [35136/60000 (78%)]	 Batch 1098 Loss: 0.473194
Train Epoch: 0 Iteration: 1100 [35200/60000 (78%)]	 Batch 1100 Loss: 0.199517
Train Epoch: 0 Iteration: 1102 [35264/60000 (78%)]	 Batch 1102 Loss: 0.057763
Train Epoch: 0 Iteration: 1104 [35328/60000 (78%)]	 Batch 1104 Loss: 0.062312
Train Epoch: 0 Iteration: 1106 [35392/60000 (79%)]	 Batch 1106 Loss: 0.188744
Train Epoch: 0 Iteration: 1108 [35456/60000 (79%)]	 Batch 1108 Loss: 0.273356
Train Epoch: 0 Iteration: 1110 [35520/60000 (79%)]	 Batch 1110 Loss: 0.962419
Train Epoch: 0 Iteration: 1112 [35584/60000 (79%)]	 Batch 1112 Loss: 0.478374
Train Epoch: 0 Iteration: 1114 [35648/60000 (79%)]	 Batch 1114 Loss: 0.873986
Train Epoch: 0 Iteration: 1116 [35712/60000 (79%)]	 Batch 1116 Loss: 0.139655
Train Epoch: 0 Iteration: 1118 [35776/60000 (79%)]	 Batch 1118 Loss: 0.154849
Train Epoch: 0 Iteration: 1120 [35840/60000 (80%)]	 Batch 1120 Loss: 0.523061
Train Epoch: 0 Iteration: 1122 [35904/60000 (80%)]	 Batch 1122 Loss: 0.132076
Train Epoch: 0 Iteration: 1124 [35968/60000 (80%)]	 Batch 1124 Loss: 0.321927
Train Epoch: 0 Iteration: 1126 [36032/60000 (80%)]	 Batch 1126 Loss: 0.092691
Train Epoch: 0 Iteration: 1128 [36096/60000 (80%)]	 Batch 1128 Loss: 0.081168
Train Epoch: 0 Iteration: 1130 [36160/60000 (80%)]	 Batch 1130 Loss: 0.337698
Train Epoch: 0 Iteration: 1132 [36224/60000 (80%)]	 Batch 1132 Loss: 0.293557
Train Epoch: 0 Iteration: 1134 [36288/60000 (81%)]	 Batch 1134 Loss: 0.058811
Train Epoch: 0 Iteration: 1136 [36352/60000 (81%)]	 Batch 1136 Loss: 0.119490
Train Epoch: 0 Iteration: 1138 [36416/60000 (81%)]	 Batch 1138 Loss: 0.070119
Train Epoch: 0 Iteration: 1140 [36480/60000 (81%)]	 Batch 1140 Loss: 0.294794
Train Epoch: 0 Iteration: 1142 [36544/60000 (81%)]	 Batch 1142 Loss: 0.357449
Train Epoch: 0 Iteration: 1144 [36608/60000 (81%)]	 Batch 1144 Loss: 0.143237
Train Epoch: 0 Iteration: 1146 [36672/60000 (81%)]	 Batch 1146 Loss: 0.537908
Train Epoch: 0 Iteration: 1148 [36736/60000 (82%)]	 Batch 1148 Loss: 0.355920
Train Epoch: 0 Iteration: 1150 [36800/60000 (82%)]	 Batch 1150 Loss: 0.546730
Train Epoch: 0 Iteration: 1152 [36864/60000 (82%)]	 Batch 1152 Loss: 0.374747
Train Epoch: 0 Iteration: 1154 [36928/60000 (82%)]	 Batch 1154 Loss: 0.108639
Train Epoch: 0 Iteration: 1156 [36992/60000 (82%)]	 Batch 1156 Loss: 0.067428
Train Epoch: 0 Iteration: 1158 [37056/60000 (82%)]	 Batch 1158 Loss: 0.383052
Train Epoch: 0 Iteration: 1160 [37120/60000 (82%)]	 Batch 1160 Loss: 0.240832
Train Epoch: 0 Iteration: 1162 [37184/60000 (83%)]	 Batch 1162 Loss: 0.042164
Train Epoch: 0 Iteration: 1164 [37248/60000 (83%)]	 Batch 1164 Loss: 0.207526
Train Epoch: 0 Iteration: 1166 [37312/60000 (83%)]	 Batch 1166 Loss: 0.162508
Train Epoch: 0 Iteration: 1168 [37376/60000 (83%)]	 Batch 1168 Loss: 0.251709
Train Epoch: 0 Iteration: 1170 [37440/60000 (83%)]	 Batch 1170 Loss: 0.235614
Train Epoch: 0 Iteration: 1172 [37504/60000 (83%)]	 Batch 1172 Loss: 0.033383
Train Epoch: 0 Iteration: 1174 [37568/60000 (83%)]	 Batch 1174 Loss: 0.037666
Train Epoch: 0 Iteration: 1176 [37632/60000 (84%)]	 Batch 1176 Loss: 0.548449
Train Epoch: 0 Iteration: 1178 [37696/60000 (84%)]	 Batch 1178 Loss: 0.196790
Train Epoch: 0 Iteration: 1180 [37760/60000 (84%)]	 Batch 1180 Loss: 0.334648
Train Epoch: 0 Iteration: 1182 [37824/60000 (84%)]	 Batch 1182 Loss: 0.146272
Train Epoch: 0 Iteration: 1184 [37888/60000 (84%)]	 Batch 1184 Loss: 0.199887
Train Epoch: 0 Iteration: 1186 [37952/60000 (84%)]	 Batch 1186 Loss: 0.456296
Train Epoch: 0 Iteration: 1188 [38016/60000 (84%)]	 Batch 1188 Loss: 0.348512
Train Epoch: 0 Iteration: 1190 [38080/60000 (85%)]	 Batch 1190 Loss: 0.266402
Train Epoch: 0 Iteration: 1192 [38144/60000 (85%)]	 Batch 1192 Loss: 0.106289
Train Epoch: 0 Iteration: 1194 [38208/60000 (85%)]	 Batch 1194 Loss: 0.202385
Train Epoch: 0 Iteration: 1196 [38272/60000 (85%)]	 Batch 1196 Loss: 0.098754
Train Epoch: 0 Iteration: 1198 [38336/60000 (85%)]	 Batch 1198 Loss: 0.376294
Train Epoch: 0 Iteration: 1200 [38400/60000 (85%)]	 Batch 1200 Loss: 0.154553
Train Epoch: 0 Iteration: 1202 [38464/60000 (85%)]	 Batch 1202 Loss: 0.218929
Train Epoch: 0 Iteration: 1204 [38528/60000 (86%)]	 Batch 1204 Loss: 0.250261
Train Epoch: 0 Iteration: 1206 [38592/60000 (86%)]	 Batch 1206 Loss: 0.162963
Train Epoch: 0 Iteration: 1208 [38656/60000 (86%)]	 Batch 1208 Loss: 0.163505
Train Epoch: 0 Iteration: 1210 [38720/60000 (86%)]	 Batch 1210 Loss: 0.114375
Train Epoch: 0 Iteration: 1212 [38784/60000 (86%)]	 Batch 1212 Loss: 0.079348
Train Epoch: 0 Iteration: 1214 [38848/60000 (86%)]	 Batch 1214 Loss: 0.255512
Train Epoch: 0 Iteration: 1216 [38912/60000 (86%)]	 Batch 1216 Loss: 0.354496
Train Epoch: 0 Iteration: 1218 [38976/60000 (87%)]	 Batch 1218 Loss: 0.101204
Train Epoch: 0 Iteration: 1220 [39040/60000 (87%)]	 Batch 1220 Loss: 0.254613
Train Epoch: 0 Iteration: 1222 [39104/60000 (87%)]	 Batch 1222 Loss: 0.181120
Train Epoch: 0 Iteration: 1224 [39168/60000 (87%)]	 Batch 1224 Loss: 0.284818
Train Epoch: 0 Iteration: 1226 [39232/60000 (87%)]	 Batch 1226 Loss: 0.110015
Train Epoch: 0 Iteration: 1228 [39296/60000 (87%)]	 Batch 1228 Loss: 0.078141
Train Epoch: 0 Iteration: 1230 [39360/60000 (87%)]	 Batch 1230 Loss: 0.282859
Train Epoch: 0 Iteration: 1232 [39424/60000 (88%)]	 Batch 1232 Loss: 0.098712
Train Epoch: 0 Iteration: 1234 [39488/60000 (88%)]	 Batch 1234 Loss: 0.037479
Train Epoch: 0 Iteration: 1236 [39552/60000 (88%)]	 Batch 1236 Loss: 0.350445
Train Epoch: 0 Iteration: 1238 [39616/60000 (88%)]	 Batch 1238 Loss: 0.568908
Train Epoch: 0 Iteration: 1240 [39680/60000 (88%)]	 Batch 1240 Loss: 0.099973
Train Epoch: 0 Iteration: 1242 [39744/60000 (88%)]	 Batch 1242 Loss: 0.188068
Train Epoch: 0 Iteration: 1244 [39808/60000 (88%)]	 Batch 1244 Loss: 0.683209
Train Epoch: 0 Iteration: 1246 [39872/60000 (89%)]	 Batch 1246 Loss: 0.080164
Train Epoch: 0 Iteration: 1248 [39936/60000 (89%)]	 Batch 1248 Loss: 0.302528
Train Epoch: 0 Iteration: 1250 [40000/60000 (89%)]	 Batch 1250 Loss: 0.198051
Train Epoch: 0 Iteration: 1252 [40064/60000 (89%)]	 Batch 1252 Loss: 0.077514
Train Epoch: 0 Iteration: 1254 [40128/60000 (89%)]	 Batch 1254 Loss: 0.120425
Train Epoch: 0 Iteration: 1256 [40192/60000 (89%)]	 Batch 1256 Loss: 0.520553
Train Epoch: 0 Iteration: 1258 [40256/60000 (89%)]	 Batch 1258 Loss: 0.140488
Train Epoch: 0 Iteration: 1260 [40320/60000 (90%)]	 Batch 1260 Loss: 0.200333
Train Epoch: 0 Iteration: 1262 [40384/60000 (90%)]	 Batch 1262 Loss: 0.118098
Train Epoch: 0 Iteration: 1264 [40448/60000 (90%)]	 Batch 1264 Loss: 0.231859
Train Epoch: 0 Iteration: 1266 [40512/60000 (90%)]	 Batch 1266 Loss: 0.433257
Train Epoch: 0 Iteration: 1268 [40576/60000 (90%)]	 Batch 1268 Loss: 0.116465
Train Epoch: 0 Iteration: 1270 [40640/60000 (90%)]	 Batch 1270 Loss: 0.349866
Train Epoch: 0 Iteration: 1272 [40704/60000 (90%)]	 Batch 1272 Loss: 0.308767
Train Epoch: 0 Iteration: 1274 [40768/60000 (91%)]	 Batch 1274 Loss: 0.141666
Train Epoch: 0 Iteration: 1276 [40832/60000 (91%)]	 Batch 1276 Loss: 0.265170
Train Epoch: 0 Iteration: 1278 [40896/60000 (91%)]	 Batch 1278 Loss: 0.100065
Train Epoch: 0 Iteration: 1280 [40960/60000 (91%)]	 Batch 1280 Loss: 0.135186
Train Epoch: 0 Iteration: 1282 [41024/60000 (91%)]	 Batch 1282 Loss: 0.072550
Train Epoch: 0 Iteration: 1284 [41088/60000 (91%)]	 Batch 1284 Loss: 0.202018
Train Epoch: 0 Iteration: 1286 [41152/60000 (91%)]	 Batch 1286 Loss: 0.276372
Train Epoch: 0 Iteration: 1288 [41216/60000 (92%)]	 Batch 1288 Loss: 0.424799
Train Epoch: 0 Iteration: 1290 [41280/60000 (92%)]	 Batch 1290 Loss: 0.044740
Train Epoch: 0 Iteration: 1292 [41344/60000 (92%)]	 Batch 1292 Loss: 0.405273
Train Epoch: 0 Iteration: 1294 [41408/60000 (92%)]	 Batch 1294 Loss: 0.218355
Train Epoch: 0 Iteration: 1296 [41472/60000 (92%)]	 Batch 1296 Loss: 0.115049
Train Epoch: 0 Iteration: 1298 [41536/60000 (92%)]	 Batch 1298 Loss: 0.118013
Train Epoch: 0 Iteration: 1300 [41600/60000 (92%)]	 Batch 1300 Loss: 0.168949
Train Epoch: 0 Iteration: 1302 [41664/60000 (93%)]	 Batch 1302 Loss: 0.090451
Train Epoch: 0 Iteration: 1304 [41728/60000 (93%)]	 Batch 1304 Loss: 0.255182
Train Epoch: 0 Iteration: 1306 [41792/60000 (93%)]	 Batch 1306 Loss: 0.250366
Train Epoch: 0 Iteration: 1308 [41856/60000 (93%)]	 Batch 1308 Loss: 0.359202
Train Epoch: 0 Iteration: 1310 [41920/60000 (93%)]	 Batch 1310 Loss: 0.235792
Train Epoch: 0 Iteration: 1312 [41984/60000 (93%)]	 Batch 1312 Loss: 0.098437
Train Epoch: 0 Iteration: 1314 [42048/60000 (93%)]	 Batch 1314 Loss: 0.385499
Train Epoch: 0 Iteration: 1316 [42112/60000 (94%)]	 Batch 1316 Loss: 0.189393
Train Epoch: 0 Iteration: 1318 [42176/60000 (94%)]	 Batch 1318 Loss: 0.111677
Train Epoch: 0 Iteration: 1320 [42240/60000 (94%)]	 Batch 1320 Loss: 0.047678
Train Epoch: 0 Iteration: 1322 [42304/60000 (94%)]	 Batch 1322 Loss: 0.059558
Train Epoch: 0 Iteration: 1324 [42368/60000 (94%)]	 Batch 1324 Loss: 0.138182
Train Epoch: 0 Iteration: 1326 [42432/60000 (94%)]	 Batch 1326 Loss: 0.445862
Train Epoch: 0 Iteration: 1328 [42496/60000 (94%)]	 Batch 1328 Loss: 0.118511
Train Epoch: 0 Iteration: 1330 [42560/60000 (95%)]	 Batch 1330 Loss: 0.340148
Train Epoch: 0 Iteration: 1332 [42624/60000 (95%)]	 Batch 1332 Loss: 0.285283
Train Epoch: 0 Iteration: 1334 [42688/60000 (95%)]	 Batch 1334 Loss: 0.166246
Train Epoch: 0 Iteration: 1336 [42752/60000 (95%)]	 Batch 1336 Loss: 0.240505
Train Epoch: 0 Iteration: 1338 [42816/60000 (95%)]	 Batch 1338 Loss: 0.300946
Train Epoch: 0 Iteration: 1340 [42880/60000 (95%)]	 Batch 1340 Loss: 0.200295
Train Epoch: 0 Iteration: 1342 [42944/60000 (95%)]	 Batch 1342 Loss: 0.044805
Train Epoch: 0 Iteration: 1344 [43008/60000 (96%)]	 Batch 1344 Loss: 0.195159
Train Epoch: 0 Iteration: 1346 [43072/60000 (96%)]	 Batch 1346 Loss: 0.120814
Train Epoch: 0 Iteration: 1348 [43136/60000 (96%)]	 Batch 1348 Loss: 0.391977
Train Epoch: 0 Iteration: 1350 [43200/60000 (96%)]	 Batch 1350 Loss: 0.507524
Train Epoch: 0 Iteration: 1352 [43264/60000 (96%)]	 Batch 1352 Loss: 0.332863
Train Epoch: 0 Iteration: 1354 [43328/60000 (96%)]	 Batch 1354 Loss: 0.299821
Train Epoch: 0 Iteration: 1356 [43392/60000 (96%)]	 Batch 1356 Loss: 0.364965
Train Epoch: 0 Iteration: 1358 [43456/60000 (97%)]	 Batch 1358 Loss: 0.307401
Train Epoch: 0 Iteration: 1360 [43520/60000 (97%)]	 Batch 1360 Loss: 0.179301
Train Epoch: 0 Iteration: 1362 [43584/60000 (97%)]	 Batch 1362 Loss: 0.605133
Train Epoch: 0 Iteration: 1364 [43648/60000 (97%)]	 Batch 1364 Loss: 0.289488
Train Epoch: 0 Iteration: 1366 [43712/60000 (97%)]	 Batch 1366 Loss: 0.345346
Train Epoch: 0 Iteration: 1368 [43776/60000 (97%)]	 Batch 1368 Loss: 0.393819
Train Epoch: 0 Iteration: 1370 [43840/60000 (97%)]	 Batch 1370 Loss: 0.093415
Train Epoch: 0 Iteration: 1372 [43904/60000 (98%)]	 Batch 1372 Loss: 0.196852
Train Epoch: 0 Iteration: 1374 [43968/60000 (98%)]	 Batch 1374 Loss: 0.153925
Train Epoch: 0 Iteration: 1376 [44032/60000 (98%)]	 Batch 1376 Loss: 0.132340
Train Epoch: 0 Iteration: 1378 [44096/60000 (98%)]	 Batch 1378 Loss: 0.432091
Train Epoch: 0 Iteration: 1380 [44160/60000 (98%)]	 Batch 1380 Loss: 0.108310
Train Epoch: 0 Iteration: 1382 [44224/60000 (98%)]	 Batch 1382 Loss: 0.148525
Train Epoch: 0 Iteration: 1384 [44288/60000 (98%)]	 Batch 1384 Loss: 0.064934
Train Epoch: 0 Iteration: 1386 [44352/60000 (99%)]	 Batch 1386 Loss: 0.238007
Train Epoch: 0 Iteration: 1388 [44416/60000 (99%)]	 Batch 1388 Loss: 0.156020
Train Epoch: 0 Iteration: 1390 [44480/60000 (99%)]	 Batch 1390 Loss: 0.098824
Train Epoch: 0 Iteration: 1392 [44544/60000 (99%)]	 Batch 1392 Loss: 0.187560
Train Epoch: 0 Iteration: 1394 [44608/60000 (99%)]	 Batch 1394 Loss: 0.131854
Train Epoch: 0 Iteration: 1396 [44672/60000 (99%)]	 Batch 1396 Loss: 0.105317
Train Epoch: 0 Iteration: 1398 [44736/60000 (99%)]	 Batch 1398 Loss: 0.153596
Train Epoch: 0 Iteration: 1400 [44800/60000 (100%)]	 Batch 1400 Loss: 0.472428
Train Epoch: 0 Iteration: 1402 [44864/60000 (100%)]	 Batch 1402 Loss: 0.098099
Train Epoch: 0 Iteration: 1404 [44928/60000 (100%)]	 Batch 1404 Loss: 0.182932
Train Epoch: 0 Iteration: 1406 [44992/60000 (100%)]	 Batch 1406 Loss: 0.021302


----------------- Epoch 0 -----------------

15000
validation computation time: 0.0  minutes
Confusion Matrix
tensor([[1499,    0,   20,    5,    4,    7,   13,    4,   22,   16],
        [   0, 1617,    5,    4,    5,    3,    3,    4,   20,    2],
        [   4,   13, 1352,   25,    2,    4,    6,   11,    9,    1],
        [   2,    0,   12, 1293,    1,   10,    0,    2,   32,   14],
        [   3,    4,   15,    0, 1272,    3,   14,    6,    4,   19],
        [  10,    5,    8,  102,    3, 1311,   18,    9,   56,   18],
        [   9,    0,   15,    6,   32,   22, 1417,    0,   18,    2],
        [   3,   25,   43,   43,   11,    2,    1, 1393,   14,   67],
        [   3,   22,   14,   13,    4,   11,    2,    3, 1256,    9],
        [   2,    6,    1,   13,  144,    5,    0,   21,   21, 1401]])
class 0 accuracy: 97.6547%
class 1 accuracy: 95.5674%
class 2 accuracy: 91.0438%
class 3 accuracy: 85.9707%
class 4 accuracy: 86.0622%
class 5 accuracy: 95.1379%
class 6 accuracy: 96.1330%
class 7 accuracy: 95.8706%
class 8 accuracy: 86.5014%
class 9 accuracy: 90.4454%

Validation Loss: 0.2647, Accuracy: 13811/15000 (92%)
Training Loss:0.3169
Best Accuracy: 92.073333%
Time Elapsed: 0h 0m 13s

--------------------------------------------------------


Train Epoch: 1 Iteration: 2 [64/60000 (0%)]	 Batch 2 Loss: 0.241268
Train Epoch: 1 Iteration: 4 [128/60000 (0%)]	 Batch 4 Loss: 0.031463
Train Epoch: 1 Iteration: 6 [192/60000 (0%)]	 Batch 6 Loss: 0.176972
Train Epoch: 1 Iteration: 8 [256/60000 (1%)]	 Batch 8 Loss: 0.221756
Train Epoch: 1 Iteration: 10 [320/60000 (1%)]	 Batch 10 Loss: 0.206243
Train Epoch: 1 Iteration: 12 [384/60000 (1%)]	 Batch 12 Loss: 0.291619
Train Epoch: 1 Iteration: 14 [448/60000 (1%)]	 Batch 14 Loss: 0.079987
Train Epoch: 1 Iteration: 16 [512/60000 (1%)]	 Batch 16 Loss: 0.065672
Train Epoch: 1 Iteration: 18 [576/60000 (1%)]	 Batch 18 Loss: 0.229174
Train Epoch: 1 Iteration: 20 [640/60000 (1%)]	 Batch 20 Loss: 0.325608
Train Epoch: 1 Iteration: 22 [704/60000 (2%)]	 Batch 22 Loss: 0.350479
Train Epoch: 1 Iteration: 24 [768/60000 (2%)]	 Batch 24 Loss: 0.285756
Train Epoch: 1 Iteration: 26 [832/60000 (2%)]	 Batch 26 Loss: 0.354305
Train Epoch: 1 Iteration: 28 [896/60000 (2%)]	 Batch 28 Loss: 0.080863
Train Epoch: 1 Iteration: 30 [960/60000 (2%)]	 Batch 30 Loss: 0.200898
Train Epoch: 1 Iteration: 32 [1024/60000 (2%)]	 Batch 32 Loss: 0.131888
Train Epoch: 1 Iteration: 34 [1088/60000 (2%)]	 Batch 34 Loss: 0.188096
Train Epoch: 1 Iteration: 36 [1152/60000 (3%)]	 Batch 36 Loss: 0.241739
Train Epoch: 1 Iteration: 38 [1216/60000 (3%)]	 Batch 38 Loss: 0.069402
Train Epoch: 1 Iteration: 40 [1280/60000 (3%)]	 Batch 40 Loss: 0.054323
Train Epoch: 1 Iteration: 42 [1344/60000 (3%)]	 Batch 42 Loss: 0.382283
Train Epoch: 1 Iteration: 44 [1408/60000 (3%)]	 Batch 44 Loss: 0.099039
Train Epoch: 1 Iteration: 46 [1472/60000 (3%)]	 Batch 46 Loss: 0.063619
Train Epoch: 1 Iteration: 48 [1536/60000 (3%)]	 Batch 48 Loss: 0.326551
Train Epoch: 1 Iteration: 50 [1600/60000 (4%)]	 Batch 50 Loss: 0.059012
Train Epoch: 1 Iteration: 52 [1664/60000 (4%)]	 Batch 52 Loss: 0.192222
Train Epoch: 1 Iteration: 54 [1728/60000 (4%)]	 Batch 54 Loss: 0.090136
Train Epoch: 1 Iteration: 56 [1792/60000 (4%)]	 Batch 56 Loss: 0.115253
Train Epoch: 1 Iteration: 58 [1856/60000 (4%)]	 Batch 58 Loss: 0.384706
Train Epoch: 1 Iteration: 60 [1920/60000 (4%)]	 Batch 60 Loss: 0.309682
Train Epoch: 1 Iteration: 62 [1984/60000 (4%)]	 Batch 62 Loss: 0.551205
Train Epoch: 1 Iteration: 64 [2048/60000 (5%)]	 Batch 64 Loss: 0.096317
Train Epoch: 1 Iteration: 66 [2112/60000 (5%)]	 Batch 66 Loss: 0.083481
Train Epoch: 1 Iteration: 68 [2176/60000 (5%)]	 Batch 68 Loss: 0.161833
Train Epoch: 1 Iteration: 70 [2240/60000 (5%)]	 Batch 70 Loss: 0.346716
Train Epoch: 1 Iteration: 72 [2304/60000 (5%)]	 Batch 72 Loss: 0.086734
Train Epoch: 1 Iteration: 74 [2368/60000 (5%)]	 Batch 74 Loss: 0.326850
Train Epoch: 1 Iteration: 76 [2432/60000 (5%)]	 Batch 76 Loss: 0.379450
Train Epoch: 1 Iteration: 78 [2496/60000 (6%)]	 Batch 78 Loss: 0.380743
Train Epoch: 1 Iteration: 80 [2560/60000 (6%)]	 Batch 80 Loss: 0.028388
Train Epoch: 1 Iteration: 82 [2624/60000 (6%)]	 Batch 82 Loss: 0.092602
Train Epoch: 1 Iteration: 84 [2688/60000 (6%)]	 Batch 84 Loss: 0.063217
Train Epoch: 1 Iteration: 86 [2752/60000 (6%)]	 Batch 86 Loss: 0.474138
Train Epoch: 1 Iteration: 88 [2816/60000 (6%)]	 Batch 88 Loss: 0.057139
Train Epoch: 1 Iteration: 90 [2880/60000 (6%)]	 Batch 90 Loss: 0.086516
Train Epoch: 1 Iteration: 92 [2944/60000 (7%)]	 Batch 92 Loss: 0.303224
Train Epoch: 1 Iteration: 94 [3008/60000 (7%)]	 Batch 94 Loss: 0.314358
Train Epoch: 1 Iteration: 96 [3072/60000 (7%)]	 Batch 96 Loss: 0.220983
Train Epoch: 1 Iteration: 98 [3136/60000 (7%)]	 Batch 98 Loss: 0.124356
Train Epoch: 1 Iteration: 100 [3200/60000 (7%)]	 Batch 100 Loss: 0.120802
Train Epoch: 1 Iteration: 102 [3264/60000 (7%)]	 Batch 102 Loss: 0.227205
Train Epoch: 1 Iteration: 104 [3328/60000 (7%)]	 Batch 104 Loss: 0.258754
Train Epoch: 1 Iteration: 106 [3392/60000 (8%)]	 Batch 106 Loss: 0.191693
Train Epoch: 1 Iteration: 108 [3456/60000 (8%)]	 Batch 108 Loss: 0.241263
Train Epoch: 1 Iteration: 110 [3520/60000 (8%)]	 Batch 110 Loss: 0.010079
Train Epoch: 1 Iteration: 112 [3584/60000 (8%)]	 Batch 112 Loss: 0.277404
Train Epoch: 1 Iteration: 114 [3648/60000 (8%)]	 Batch 114 Loss: 0.032970
Train Epoch: 1 Iteration: 116 [3712/60000 (8%)]	 Batch 116 Loss: 0.109407
Train Epoch: 1 Iteration: 118 [3776/60000 (8%)]	 Batch 118 Loss: 0.319564
Train Epoch: 1 Iteration: 120 [3840/60000 (9%)]	 Batch 120 Loss: 0.218310
Train Epoch: 1 Iteration: 122 [3904/60000 (9%)]	 Batch 122 Loss: 0.182876
Train Epoch: 1 Iteration: 124 [3968/60000 (9%)]	 Batch 124 Loss: 0.414263
Train Epoch: 1 Iteration: 126 [4032/60000 (9%)]	 Batch 126 Loss: 0.096018
Train Epoch: 1 Iteration: 128 [4096/60000 (9%)]	 Batch 128 Loss: 0.132596
Train Epoch: 1 Iteration: 130 [4160/60000 (9%)]	 Batch 130 Loss: 0.131439
Train Epoch: 1 Iteration: 132 [4224/60000 (9%)]	 Batch 132 Loss: 0.096817
Train Epoch: 1 Iteration: 134 [4288/60000 (10%)]	 Batch 134 Loss: 0.059662
Train Epoch: 1 Iteration: 136 [4352/60000 (10%)]	 Batch 136 Loss: 0.362159
Train Epoch: 1 Iteration: 138 [4416/60000 (10%)]	 Batch 138 Loss: 0.026537
Train Epoch: 1 Iteration: 140 [4480/60000 (10%)]	 Batch 140 Loss: 0.132739
Train Epoch: 1 Iteration: 142 [4544/60000 (10%)]	 Batch 142 Loss: 0.361870
Train Epoch: 1 Iteration: 144 [4608/60000 (10%)]	 Batch 144 Loss: 0.104719
Train Epoch: 1 Iteration: 146 [4672/60000 (10%)]	 Batch 146 Loss: 0.123045
Train Epoch: 1 Iteration: 148 [4736/60000 (11%)]	 Batch 148 Loss: 0.145488
Train Epoch: 1 Iteration: 150 [4800/60000 (11%)]	 Batch 150 Loss: 0.024070
Train Epoch: 1 Iteration: 152 [4864/60000 (11%)]	 Batch 152 Loss: 0.341463
Train Epoch: 1 Iteration: 154 [4928/60000 (11%)]	 Batch 154 Loss: 0.220387
Train Epoch: 1 Iteration: 156 [4992/60000 (11%)]	 Batch 156 Loss: 0.125082
Train Epoch: 1 Iteration: 158 [5056/60000 (11%)]	 Batch 158 Loss: 0.085614
Train Epoch: 1 Iteration: 160 [5120/60000 (11%)]	 Batch 160 Loss: 0.108368
Train Epoch: 1 Iteration: 162 [5184/60000 (12%)]	 Batch 162 Loss: 0.284028
Train Epoch: 1 Iteration: 164 [5248/60000 (12%)]	 Batch 164 Loss: 0.258551
Train Epoch: 1 Iteration: 166 [5312/60000 (12%)]	 Batch 166 Loss: 0.030210
Train Epoch: 1 Iteration: 168 [5376/60000 (12%)]	 Batch 168 Loss: 0.147085
Train Epoch: 1 Iteration: 170 [5440/60000 (12%)]	 Batch 170 Loss: 0.077465
Train Epoch: 1 Iteration: 172 [5504/60000 (12%)]	 Batch 172 Loss: 0.106508
Train Epoch: 1 Iteration: 174 [5568/60000 (12%)]	 Batch 174 Loss: 0.237224
Train Epoch: 1 Iteration: 176 [5632/60000 (13%)]	 Batch 176 Loss: 0.298847
Train Epoch: 1 Iteration: 178 [5696/60000 (13%)]	 Batch 178 Loss: 0.283936
Train Epoch: 1 Iteration: 180 [5760/60000 (13%)]	 Batch 180 Loss: 0.328689
Train Epoch: 1 Iteration: 182 [5824/60000 (13%)]	 Batch 182 Loss: 0.068376
Train Epoch: 1 Iteration: 184 [5888/60000 (13%)]	 Batch 184 Loss: 0.234561
Train Epoch: 1 Iteration: 186 [5952/60000 (13%)]	 Batch 186 Loss: 0.137571
Train Epoch: 1 Iteration: 188 [6016/60000 (13%)]	 Batch 188 Loss: 0.132261
Train Epoch: 1 Iteration: 190 [6080/60000 (14%)]	 Batch 190 Loss: 0.311564
Train Epoch: 1 Iteration: 192 [6144/60000 (14%)]	 Batch 192 Loss: 0.221376
Train Epoch: 1 Iteration: 194 [6208/60000 (14%)]	 Batch 194 Loss: 0.626263
Train Epoch: 1 Iteration: 196 [6272/60000 (14%)]	 Batch 196 Loss: 0.218344
Train Epoch: 1 Iteration: 198 [6336/60000 (14%)]	 Batch 198 Loss: 0.076787
Train Epoch: 1 Iteration: 200 [6400/60000 (14%)]	 Batch 200 Loss: 0.333041
Train Epoch: 1 Iteration: 202 [6464/60000 (14%)]	 Batch 202 Loss: 0.738022
Train Epoch: 1 Iteration: 204 [6528/60000 (14%)]	 Batch 204 Loss: 0.127606
Train Epoch: 1 Iteration: 206 [6592/60000 (15%)]	 Batch 206 Loss: 0.463176
Train Epoch: 1 Iteration: 208 [6656/60000 (15%)]	 Batch 208 Loss: 0.036788
Train Epoch: 1 Iteration: 210 [6720/60000 (15%)]	 Batch 210 Loss: 0.154237
Train Epoch: 1 Iteration: 212 [6784/60000 (15%)]	 Batch 212 Loss: 0.070388
Train Epoch: 1 Iteration: 214 [6848/60000 (15%)]	 Batch 214 Loss: 0.283191
Train Epoch: 1 Iteration: 216 [6912/60000 (15%)]	 Batch 216 Loss: 0.035808
Train Epoch: 1 Iteration: 218 [6976/60000 (15%)]	 Batch 218 Loss: 0.322517
Train Epoch: 1 Iteration: 220 [7040/60000 (16%)]	 Batch 220 Loss: 0.273934
Train Epoch: 1 Iteration: 222 [7104/60000 (16%)]	 Batch 222 Loss: 0.097811
Train Epoch: 1 Iteration: 224 [7168/60000 (16%)]	 Batch 224 Loss: 0.107073
Train Epoch: 1 Iteration: 226 [7232/60000 (16%)]	 Batch 226 Loss: 0.697145
Train Epoch: 1 Iteration: 228 [7296/60000 (16%)]	 Batch 228 Loss: 0.043104
Train Epoch: 1 Iteration: 230 [7360/60000 (16%)]	 Batch 230 Loss: 0.210243
Train Epoch: 1 Iteration: 232 [7424/60000 (16%)]	 Batch 232 Loss: 0.246362
Train Epoch: 1 Iteration: 234 [7488/60000 (17%)]	 Batch 234 Loss: 0.176348
Train Epoch: 1 Iteration: 236 [7552/60000 (17%)]	 Batch 236 Loss: 0.358461
Train Epoch: 1 Iteration: 238 [7616/60000 (17%)]	 Batch 238 Loss: 0.188143
Train Epoch: 1 Iteration: 240 [7680/60000 (17%)]	 Batch 240 Loss: 0.237900
Train Epoch: 1 Iteration: 242 [7744/60000 (17%)]	 Batch 242 Loss: 0.311570
Train Epoch: 1 Iteration: 244 [7808/60000 (17%)]	 Batch 244 Loss: 0.116398
Train Epoch: 1 Iteration: 246 [7872/60000 (17%)]	 Batch 246 Loss: 0.149074
Train Epoch: 1 Iteration: 248 [7936/60000 (18%)]	 Batch 248 Loss: 0.449725
Train Epoch: 1 Iteration: 250 [8000/60000 (18%)]	 Batch 250 Loss: 0.172895
Train Epoch: 1 Iteration: 252 [8064/60000 (18%)]	 Batch 252 Loss: 0.165688
Train Epoch: 1 Iteration: 254 [8128/60000 (18%)]	 Batch 254 Loss: 0.095446
Train Epoch: 1 Iteration: 256 [8192/60000 (18%)]	 Batch 256 Loss: 0.283096
Train Epoch: 1 Iteration: 258 [8256/60000 (18%)]	 Batch 258 Loss: 0.237958
Train Epoch: 1 Iteration: 260 [8320/60000 (18%)]	 Batch 260 Loss: 0.088371
Train Epoch: 1 Iteration: 262 [8384/60000 (19%)]	 Batch 262 Loss: 0.377669
Train Epoch: 1 Iteration: 264 [8448/60000 (19%)]	 Batch 264 Loss: 0.202670
Train Epoch: 1 Iteration: 266 [8512/60000 (19%)]	 Batch 266 Loss: 0.254466
Train Epoch: 1 Iteration: 268 [8576/60000 (19%)]	 Batch 268 Loss: 0.042427
Train Epoch: 1 Iteration: 270 [8640/60000 (19%)]	 Batch 270 Loss: 0.370106
Train Epoch: 1 Iteration: 272 [8704/60000 (19%)]	 Batch 272 Loss: 0.053622
Train Epoch: 1 Iteration: 274 [8768/60000 (19%)]	 Batch 274 Loss: 0.331244
Train Epoch: 1 Iteration: 276 [8832/60000 (20%)]	 Batch 276 Loss: 0.219979
Train Epoch: 1 Iteration: 278 [8896/60000 (20%)]	 Batch 278 Loss: 0.098789
Train Epoch: 1 Iteration: 280 [8960/60000 (20%)]	 Batch 280 Loss: 0.178974
Train Epoch: 1 Iteration: 282 [9024/60000 (20%)]	 Batch 282 Loss: 0.140948
Train Epoch: 1 Iteration: 284 [9088/60000 (20%)]	 Batch 284 Loss: 0.567731
Train Epoch: 1 Iteration: 286 [9152/60000 (20%)]	 Batch 286 Loss: 0.135504
Train Epoch: 1 Iteration: 288 [9216/60000 (20%)]	 Batch 288 Loss: 0.336185
Train Epoch: 1 Iteration: 290 [9280/60000 (21%)]	 Batch 290 Loss: 0.122939
Train Epoch: 1 Iteration: 292 [9344/60000 (21%)]	 Batch 292 Loss: 0.456293
Train Epoch: 1 Iteration: 294 [9408/60000 (21%)]	 Batch 294 Loss: 0.209467
Train Epoch: 1 Iteration: 296 [9472/60000 (21%)]	 Batch 296 Loss: 0.071967
Train Epoch: 1 Iteration: 298 [9536/60000 (21%)]	 Batch 298 Loss: 0.120966
Train Epoch: 1 Iteration: 300 [9600/60000 (21%)]	 Batch 300 Loss: 0.089839
Train Epoch: 1 Iteration: 302 [9664/60000 (21%)]	 Batch 302 Loss: 0.213025
Train Epoch: 1 Iteration: 304 [9728/60000 (22%)]	 Batch 304 Loss: 0.240279
Train Epoch: 1 Iteration: 306 [9792/60000 (22%)]	 Batch 306 Loss: 0.066799
Train Epoch: 1 Iteration: 308 [9856/60000 (22%)]	 Batch 308 Loss: 0.059412
Train Epoch: 1 Iteration: 310 [9920/60000 (22%)]	 Batch 310 Loss: 0.085247
Train Epoch: 1 Iteration: 312 [9984/60000 (22%)]	 Batch 312 Loss: 0.030141
Train Epoch: 1 Iteration: 314 [10048/60000 (22%)]	 Batch 314 Loss: 0.067276
Train Epoch: 1 Iteration: 316 [10112/60000 (22%)]	 Batch 316 Loss: 0.210519
Train Epoch: 1 Iteration: 318 [10176/60000 (23%)]	 Batch 318 Loss: 0.235988
Train Epoch: 1 Iteration: 320 [10240/60000 (23%)]	 Batch 320 Loss: 0.278583
Train Epoch: 1 Iteration: 322 [10304/60000 (23%)]	 Batch 322 Loss: 0.324492
Train Epoch: 1 Iteration: 324 [10368/60000 (23%)]	 Batch 324 Loss: 0.060725
Train Epoch: 1 Iteration: 326 [10432/60000 (23%)]	 Batch 326 Loss: 0.217059
Train Epoch: 1 Iteration: 328 [10496/60000 (23%)]	 Batch 328 Loss: 0.055005
Train Epoch: 1 Iteration: 330 [10560/60000 (23%)]	 Batch 330 Loss: 0.102576
Train Epoch: 1 Iteration: 332 [10624/60000 (24%)]	 Batch 332 Loss: 0.259796
Train Epoch: 1 Iteration: 334 [10688/60000 (24%)]	 Batch 334 Loss: 0.148733
Train Epoch: 1 Iteration: 336 [10752/60000 (24%)]	 Batch 336 Loss: 0.335771
Train Epoch: 1 Iteration: 338 [10816/60000 (24%)]	 Batch 338 Loss: 0.376461
Train Epoch: 1 Iteration: 340 [10880/60000 (24%)]	 Batch 340 Loss: 0.033038
Train Epoch: 1 Iteration: 342 [10944/60000 (24%)]	 Batch 342 Loss: 0.303361
Train Epoch: 1 Iteration: 344 [11008/60000 (24%)]	 Batch 344 Loss: 0.043250
Train Epoch: 1 Iteration: 346 [11072/60000 (25%)]	 Batch 346 Loss: 0.058805
Train Epoch: 1 Iteration: 348 [11136/60000 (25%)]	 Batch 348 Loss: 0.285928
Train Epoch: 1 Iteration: 350 [11200/60000 (25%)]	 Batch 350 Loss: 0.138359
Train Epoch: 1 Iteration: 352 [11264/60000 (25%)]	 Batch 352 Loss: 0.167879
Train Epoch: 1 Iteration: 354 [11328/60000 (25%)]	 Batch 354 Loss: 0.250360
Train Epoch: 1 Iteration: 356 [11392/60000 (25%)]	 Batch 356 Loss: 0.072458
Train Epoch: 1 Iteration: 358 [11456/60000 (25%)]	 Batch 358 Loss: 0.014620
Train Epoch: 1 Iteration: 360 [11520/60000 (26%)]	 Batch 360 Loss: 0.088853
Train Epoch: 1 Iteration: 362 [11584/60000 (26%)]	 Batch 362 Loss: 0.484966
Train Epoch: 1 Iteration: 364 [11648/60000 (26%)]	 Batch 364 Loss: 0.360035
Train Epoch: 1 Iteration: 366 [11712/60000 (26%)]	 Batch 366 Loss: 0.564471
Train Epoch: 1 Iteration: 368 [11776/60000 (26%)]	 Batch 368 Loss: 0.246329
Train Epoch: 1 Iteration: 370 [11840/60000 (26%)]	 Batch 370 Loss: 0.255025
Train Epoch: 1 Iteration: 372 [11904/60000 (26%)]	 Batch 372 Loss: 0.109651
Train Epoch: 1 Iteration: 374 [11968/60000 (27%)]	 Batch 374 Loss: 0.268730
Train Epoch: 1 Iteration: 376 [12032/60000 (27%)]	 Batch 376 Loss: 0.344585
Train Epoch: 1 Iteration: 378 [12096/60000 (27%)]	 Batch 378 Loss: 0.171899
Train Epoch: 1 Iteration: 380 [12160/60000 (27%)]	 Batch 380 Loss: 0.594861
Train Epoch: 1 Iteration: 382 [12224/60000 (27%)]	 Batch 382 Loss: 0.053211
Train Epoch: 1 Iteration: 384 [12288/60000 (27%)]	 Batch 384 Loss: 0.342286
Train Epoch: 1 Iteration: 386 [12352/60000 (27%)]	 Batch 386 Loss: 0.409812
Train Epoch: 1 Iteration: 388 [12416/60000 (28%)]	 Batch 388 Loss: 0.401275
Train Epoch: 1 Iteration: 390 [12480/60000 (28%)]	 Batch 390 Loss: 0.065599
Train Epoch: 1 Iteration: 392 [12544/60000 (28%)]	 Batch 392 Loss: 0.151798
Train Epoch: 1 Iteration: 394 [12608/60000 (28%)]	 Batch 394 Loss: 0.274085
Train Epoch: 1 Iteration: 396 [12672/60000 (28%)]	 Batch 396 Loss: 0.331917
Train Epoch: 1 Iteration: 398 [12736/60000 (28%)]	 Batch 398 Loss: 0.298949
Train Epoch: 1 Iteration: 400 [12800/60000 (28%)]	 Batch 400 Loss: 0.081064
Train Epoch: 1 Iteration: 402 [12864/60000 (29%)]	 Batch 402 Loss: 0.334285
Train Epoch: 1 Iteration: 404 [12928/60000 (29%)]	 Batch 404 Loss: 0.386155
Train Epoch: 1 Iteration: 406 [12992/60000 (29%)]	 Batch 406 Loss: 0.023010
Train Epoch: 1 Iteration: 408 [13056/60000 (29%)]	 Batch 408 Loss: 0.161457
Train Epoch: 1 Iteration: 410 [13120/60000 (29%)]	 Batch 410 Loss: 0.043381
Train Epoch: 1 Iteration: 412 [13184/60000 (29%)]	 Batch 412 Loss: 0.103873
Train Epoch: 1 Iteration: 414 [13248/60000 (29%)]	 Batch 414 Loss: 0.225920
Train Epoch: 1 Iteration: 416 [13312/60000 (30%)]	 Batch 416 Loss: 0.038206
Train Epoch: 1 Iteration: 418 [13376/60000 (30%)]	 Batch 418 Loss: 0.394907
Train Epoch: 1 Iteration: 420 [13440/60000 (30%)]	 Batch 420 Loss: 0.302880
Train Epoch: 1 Iteration: 422 [13504/60000 (30%)]	 Batch 422 Loss: 0.282710
Train Epoch: 1 Iteration: 424 [13568/60000 (30%)]	 Batch 424 Loss: 0.077200
Train Epoch: 1 Iteration: 426 [13632/60000 (30%)]	 Batch 426 Loss: 0.305122
Train Epoch: 1 Iteration: 428 [13696/60000 (30%)]	 Batch 428 Loss: 0.433530
Train Epoch: 1 Iteration: 430 [13760/60000 (31%)]	 Batch 430 Loss: 0.067004
Train Epoch: 1 Iteration: 432 [13824/60000 (31%)]	 Batch 432 Loss: 0.601568
Train Epoch: 1 Iteration: 434 [13888/60000 (31%)]	 Batch 434 Loss: 0.303252
Train Epoch: 1 Iteration: 436 [13952/60000 (31%)]	 Batch 436 Loss: 0.254129
Train Epoch: 1 Iteration: 438 [14016/60000 (31%)]	 Batch 438 Loss: 0.216737
Train Epoch: 1 Iteration: 440 [14080/60000 (31%)]	 Batch 440 Loss: 0.050533
Train Epoch: 1 Iteration: 442 [14144/60000 (31%)]	 Batch 442 Loss: 0.163190
Train Epoch: 1 Iteration: 444 [14208/60000 (32%)]	 Batch 444 Loss: 0.219414
Train Epoch: 1 Iteration: 446 [14272/60000 (32%)]	 Batch 446 Loss: 0.027257
Train Epoch: 1 Iteration: 448 [14336/60000 (32%)]	 Batch 448 Loss: 0.235631
Train Epoch: 1 Iteration: 450 [14400/60000 (32%)]	 Batch 450 Loss: 0.457906
Train Epoch: 1 Iteration: 452 [14464/60000 (32%)]	 Batch 452 Loss: 0.444688
Train Epoch: 1 Iteration: 454 [14528/60000 (32%)]	 Batch 454 Loss: 0.083152
Train Epoch: 1 Iteration: 456 [14592/60000 (32%)]	 Batch 456 Loss: 0.052737
Train Epoch: 1 Iteration: 458 [14656/60000 (33%)]	 Batch 458 Loss: 0.318716
Train Epoch: 1 Iteration: 460 [14720/60000 (33%)]	 Batch 460 Loss: 0.128452
Train Epoch: 1 Iteration: 462 [14784/60000 (33%)]	 Batch 462 Loss: 0.087958
Train Epoch: 1 Iteration: 464 [14848/60000 (33%)]	 Batch 464 Loss: 0.102017
Train Epoch: 1 Iteration: 466 [14912/60000 (33%)]	 Batch 466 Loss: 0.030129
Train Epoch: 1 Iteration: 468 [14976/60000 (33%)]	 Batch 468 Loss: 0.343669
Train Epoch: 1 Iteration: 470 [15040/60000 (33%)]	 Batch 470 Loss: 0.247332
Train Epoch: 1 Iteration: 472 [15104/60000 (34%)]	 Batch 472 Loss: 0.247679
Train Epoch: 1 Iteration: 474 [15168/60000 (34%)]	 Batch 474 Loss: 0.517833
Train Epoch: 1 Iteration: 476 [15232/60000 (34%)]	 Batch 476 Loss: 0.169891
Train Epoch: 1 Iteration: 478 [15296/60000 (34%)]	 Batch 478 Loss: 0.040719
Train Epoch: 1 Iteration: 480 [15360/60000 (34%)]	 Batch 480 Loss: 0.368254
Train Epoch: 1 Iteration: 482 [15424/60000 (34%)]	 Batch 482 Loss: 0.109686
Train Epoch: 1 Iteration: 484 [15488/60000 (34%)]	 Batch 484 Loss: 0.144820
Train Epoch: 1 Iteration: 486 [15552/60000 (35%)]	 Batch 486 Loss: 0.189959
Train Epoch: 1 Iteration: 488 [15616/60000 (35%)]	 Batch 488 Loss: 0.168458
Train Epoch: 1 Iteration: 490 [15680/60000 (35%)]	 Batch 490 Loss: 0.387298
Train Epoch: 1 Iteration: 492 [15744/60000 (35%)]	 Batch 492 Loss: 0.023814
Train Epoch: 1 Iteration: 494 [15808/60000 (35%)]	 Batch 494 Loss: 0.130374
Train Epoch: 1 Iteration: 496 [15872/60000 (35%)]	 Batch 496 Loss: 0.115613
Train Epoch: 1 Iteration: 498 [15936/60000 (35%)]	 Batch 498 Loss: 0.202727
Train Epoch: 1 Iteration: 500 [16000/60000 (36%)]	 Batch 500 Loss: 0.082740
Train Epoch: 1 Iteration: 502 [16064/60000 (36%)]	 Batch 502 Loss: 0.047498
Train Epoch: 1 Iteration: 504 [16128/60000 (36%)]	 Batch 504 Loss: 0.214475
Train Epoch: 1 Iteration: 506 [16192/60000 (36%)]	 Batch 506 Loss: 0.049497
Train Epoch: 1 Iteration: 508 [16256/60000 (36%)]	 Batch 508 Loss: 0.146650
Train Epoch: 1 Iteration: 510 [16320/60000 (36%)]	 Batch 510 Loss: 0.302323
Train Epoch: 1 Iteration: 512 [16384/60000 (36%)]	 Batch 512 Loss: 0.136302
Train Epoch: 1 Iteration: 514 [16448/60000 (37%)]	 Batch 514 Loss: 0.500069
Train Epoch: 1 Iteration: 516 [16512/60000 (37%)]	 Batch 516 Loss: 0.297888
Train Epoch: 1 Iteration: 518 [16576/60000 (37%)]	 Batch 518 Loss: 0.566467
Train Epoch: 1 Iteration: 520 [16640/60000 (37%)]	 Batch 520 Loss: 0.264056
Train Epoch: 1 Iteration: 522 [16704/60000 (37%)]	 Batch 522 Loss: 0.219786
Train Epoch: 1 Iteration: 524 [16768/60000 (37%)]	 Batch 524 Loss: 0.380143
Train Epoch: 1 Iteration: 526 [16832/60000 (37%)]	 Batch 526 Loss: 0.384963
Train Epoch: 1 Iteration: 528 [16896/60000 (38%)]	 Batch 528 Loss: 0.094704
Train Epoch: 1 Iteration: 530 [16960/60000 (38%)]	 Batch 530 Loss: 0.259993
Train Epoch: 1 Iteration: 532 [17024/60000 (38%)]	 Batch 532 Loss: 0.108176
Train Epoch: 1 Iteration: 534 [17088/60000 (38%)]	 Batch 534 Loss: 0.271164
Train Epoch: 1 Iteration: 536 [17152/60000 (38%)]	 Batch 536 Loss: 0.032395
Train Epoch: 1 Iteration: 538 [17216/60000 (38%)]	 Batch 538 Loss: 0.144333
Train Epoch: 1 Iteration: 540 [17280/60000 (38%)]	 Batch 540 Loss: 0.195548
Train Epoch: 1 Iteration: 542 [17344/60000 (39%)]	 Batch 542 Loss: 0.110379
Train Epoch: 1 Iteration: 544 [17408/60000 (39%)]	 Batch 544 Loss: 0.046779
Train Epoch: 1 Iteration: 546 [17472/60000 (39%)]	 Batch 546 Loss: 0.369591
Train Epoch: 1 Iteration: 548 [17536/60000 (39%)]	 Batch 548 Loss: 0.192514
Train Epoch: 1 Iteration: 550 [17600/60000 (39%)]	 Batch 550 Loss: 0.092220
Train Epoch: 1 Iteration: 552 [17664/60000 (39%)]	 Batch 552 Loss: 0.171623
Train Epoch: 1 Iteration: 554 [17728/60000 (39%)]	 Batch 554 Loss: 0.070196
Train Epoch: 1 Iteration: 556 [17792/60000 (40%)]	 Batch 556 Loss: 0.091602
Train Epoch: 1 Iteration: 558 [17856/60000 (40%)]	 Batch 558 Loss: 0.196359
Train Epoch: 1 Iteration: 560 [17920/60000 (40%)]	 Batch 560 Loss: 0.256221
Train Epoch: 1 Iteration: 562 [17984/60000 (40%)]	 Batch 562 Loss: 0.180055
Train Epoch: 1 Iteration: 564 [18048/60000 (40%)]	 Batch 564 Loss: 0.189818
Train Epoch: 1 Iteration: 566 [18112/60000 (40%)]	 Batch 566 Loss: 0.149656
Train Epoch: 1 Iteration: 568 [18176/60000 (40%)]	 Batch 568 Loss: 0.032371
Train Epoch: 1 Iteration: 570 [18240/60000 (41%)]	 Batch 570 Loss: 0.436139
Train Epoch: 1 Iteration: 572 [18304/60000 (41%)]	 Batch 572 Loss: 0.175361
Train Epoch: 1 Iteration: 574 [18368/60000 (41%)]	 Batch 574 Loss: 0.147745
Train Epoch: 1 Iteration: 576 [18432/60000 (41%)]	 Batch 576 Loss: 0.141291
Train Epoch: 1 Iteration: 578 [18496/60000 (41%)]	 Batch 578 Loss: 0.198726
Train Epoch: 1 Iteration: 580 [18560/60000 (41%)]	 Batch 580 Loss: 0.209905
Train Epoch: 1 Iteration: 582 [18624/60000 (41%)]	 Batch 582 Loss: 0.211354
Train Epoch: 1 Iteration: 584 [18688/60000 (42%)]	 Batch 584 Loss: 0.370062
Train Epoch: 1 Iteration: 586 [18752/60000 (42%)]	 Batch 586 Loss: 0.162946
Train Epoch: 1 Iteration: 588 [18816/60000 (42%)]	 Batch 588 Loss: 0.078865
Train Epoch: 1 Iteration: 590 [18880/60000 (42%)]	 Batch 590 Loss: 0.514919
Train Epoch: 1 Iteration: 592 [18944/60000 (42%)]	 Batch 592 Loss: 0.122201
Train Epoch: 1 Iteration: 594 [19008/60000 (42%)]	 Batch 594 Loss: 0.062468
Train Epoch: 1 Iteration: 596 [19072/60000 (42%)]	 Batch 596 Loss: 0.518935
Train Epoch: 1 Iteration: 598 [19136/60000 (43%)]	 Batch 598 Loss: 0.074601
Train Epoch: 1 Iteration: 600 [19200/60000 (43%)]	 Batch 600 Loss: 0.120472
Train Epoch: 1 Iteration: 602 [19264/60000 (43%)]	 Batch 602 Loss: 0.058003
Train Epoch: 1 Iteration: 604 [19328/60000 (43%)]	 Batch 604 Loss: 0.044965
Train Epoch: 1 Iteration: 606 [19392/60000 (43%)]	 Batch 606 Loss: 0.283606
Train Epoch: 1 Iteration: 608 [19456/60000 (43%)]	 Batch 608 Loss: 0.385730
Train Epoch: 1 Iteration: 610 [19520/60000 (43%)]	 Batch 610 Loss: 0.386439
Train Epoch: 1 Iteration: 612 [19584/60000 (43%)]	 Batch 612 Loss: 0.159198
Train Epoch: 1 Iteration: 614 [19648/60000 (44%)]	 Batch 614 Loss: 0.214587
Train Epoch: 1 Iteration: 616 [19712/60000 (44%)]	 Batch 616 Loss: 0.123138
Train Epoch: 1 Iteration: 618 [19776/60000 (44%)]	 Batch 618 Loss: 0.218182
Train Epoch: 1 Iteration: 620 [19840/60000 (44%)]	 Batch 620 Loss: 0.074954
Train Epoch: 1 Iteration: 622 [19904/60000 (44%)]	 Batch 622 Loss: 0.379208
Train Epoch: 1 Iteration: 624 [19968/60000 (44%)]	 Batch 624 Loss: 0.079027
Train Epoch: 1 Iteration: 626 [20032/60000 (44%)]	 Batch 626 Loss: 0.420986
Train Epoch: 1 Iteration: 628 [20096/60000 (45%)]	 Batch 628 Loss: 0.321981
Train Epoch: 1 Iteration: 630 [20160/60000 (45%)]	 Batch 630 Loss: 0.296268
Train Epoch: 1 Iteration: 632 [20224/60000 (45%)]	 Batch 632 Loss: 0.290756
Train Epoch: 1 Iteration: 634 [20288/60000 (45%)]	 Batch 634 Loss: 0.167977
Train Epoch: 1 Iteration: 636 [20352/60000 (45%)]	 Batch 636 Loss: 0.167156
Train Epoch: 1 Iteration: 638 [20416/60000 (45%)]	 Batch 638 Loss: 0.115360
Train Epoch: 1 Iteration: 640 [20480/60000 (45%)]	 Batch 640 Loss: 0.374967
Train Epoch: 1 Iteration: 642 [20544/60000 (46%)]	 Batch 642 Loss: 0.188313
Train Epoch: 1 Iteration: 644 [20608/60000 (46%)]	 Batch 644 Loss: 0.049217
Train Epoch: 1 Iteration: 646 [20672/60000 (46%)]	 Batch 646 Loss: 0.189611
Train Epoch: 1 Iteration: 648 [20736/60000 (46%)]	 Batch 648 Loss: 0.147883
Train Epoch: 1 Iteration: 650 [20800/60000 (46%)]	 Batch 650 Loss: 0.297524
Train Epoch: 1 Iteration: 652 [20864/60000 (46%)]	 Batch 652 Loss: 0.111703
Train Epoch: 1 Iteration: 654 [20928/60000 (46%)]	 Batch 654 Loss: 0.076399
Train Epoch: 1 Iteration: 656 [20992/60000 (47%)]	 Batch 656 Loss: 0.064649
Train Epoch: 1 Iteration: 658 [21056/60000 (47%)]	 Batch 658 Loss: 0.110745
Train Epoch: 1 Iteration: 660 [21120/60000 (47%)]	 Batch 660 Loss: 0.166576
Train Epoch: 1 Iteration: 662 [21184/60000 (47%)]	 Batch 662 Loss: 0.168695
Train Epoch: 1 Iteration: 664 [21248/60000 (47%)]	 Batch 664 Loss: 0.033170
Train Epoch: 1 Iteration: 666 [21312/60000 (47%)]	 Batch 666 Loss: 0.067553
Train Epoch: 1 Iteration: 668 [21376/60000 (47%)]	 Batch 668 Loss: 0.265553
Train Epoch: 1 Iteration: 670 [21440/60000 (48%)]	 Batch 670 Loss: 0.084692
Train Epoch: 1 Iteration: 672 [21504/60000 (48%)]	 Batch 672 Loss: 0.214933
Train Epoch: 1 Iteration: 674 [21568/60000 (48%)]	 Batch 674 Loss: 0.080411
Train Epoch: 1 Iteration: 676 [21632/60000 (48%)]	 Batch 676 Loss: 0.103740
Train Epoch: 1 Iteration: 678 [21696/60000 (48%)]	 Batch 678 Loss: 0.072077
Train Epoch: 1 Iteration: 680 [21760/60000 (48%)]	 Batch 680 Loss: 0.181283
Train Epoch: 1 Iteration: 682 [21824/60000 (48%)]	 Batch 682 Loss: 0.307020
Train Epoch: 1 Iteration: 684 [21888/60000 (49%)]	 Batch 684 Loss: 0.062627
Train Epoch: 1 Iteration: 686 [21952/60000 (49%)]	 Batch 686 Loss: 0.156099
Train Epoch: 1 Iteration: 688 [22016/60000 (49%)]	 Batch 688 Loss: 0.252172
Train Epoch: 1 Iteration: 690 [22080/60000 (49%)]	 Batch 690 Loss: 0.310953
Train Epoch: 1 Iteration: 692 [22144/60000 (49%)]	 Batch 692 Loss: 0.021898
Train Epoch: 1 Iteration: 694 [22208/60000 (49%)]	 Batch 694 Loss: 0.186281
Train Epoch: 1 Iteration: 696 [22272/60000 (49%)]	 Batch 696 Loss: 0.371368
Train Epoch: 1 Iteration: 698 [22336/60000 (50%)]	 Batch 698 Loss: 0.382235
Train Epoch: 1 Iteration: 700 [22400/60000 (50%)]	 Batch 700 Loss: 0.115259
Train Epoch: 1 Iteration: 702 [22464/60000 (50%)]	 Batch 702 Loss: 0.146778
Train Epoch: 1 Iteration: 704 [22528/60000 (50%)]	 Batch 704 Loss: 0.122365
Train Epoch: 1 Iteration: 706 [22592/60000 (50%)]	 Batch 706 Loss: 0.210539
Train Epoch: 1 Iteration: 708 [22656/60000 (50%)]	 Batch 708 Loss: 0.176544
Train Epoch: 1 Iteration: 710 [22720/60000 (50%)]	 Batch 710 Loss: 0.026469
Train Epoch: 1 Iteration: 712 [22784/60000 (51%)]	 Batch 712 Loss: 0.176660
Train Epoch: 1 Iteration: 714 [22848/60000 (51%)]	 Batch 714 Loss: 0.099002
Train Epoch: 1 Iteration: 716 [22912/60000 (51%)]	 Batch 716 Loss: 0.387693
Train Epoch: 1 Iteration: 718 [22976/60000 (51%)]	 Batch 718 Loss: 0.380313
Train Epoch: 1 Iteration: 720 [23040/60000 (51%)]	 Batch 720 Loss: 0.136469
Train Epoch: 1 Iteration: 722 [23104/60000 (51%)]	 Batch 722 Loss: 0.131202
Train Epoch: 1 Iteration: 724 [23168/60000 (51%)]	 Batch 724 Loss: 0.056243
Train Epoch: 1 Iteration: 726 [23232/60000 (52%)]	 Batch 726 Loss: 0.198927
Train Epoch: 1 Iteration: 728 [23296/60000 (52%)]	 Batch 728 Loss: 0.134110
Train Epoch: 1 Iteration: 730 [23360/60000 (52%)]	 Batch 730 Loss: 0.427395
Train Epoch: 1 Iteration: 732 [23424/60000 (52%)]	 Batch 732 Loss: 0.079292
Train Epoch: 1 Iteration: 734 [23488/60000 (52%)]	 Batch 734 Loss: 0.421092
Train Epoch: 1 Iteration: 736 [23552/60000 (52%)]	 Batch 736 Loss: 0.020612
Train Epoch: 1 Iteration: 738 [23616/60000 (52%)]	 Batch 738 Loss: 0.477457
Train Epoch: 1 Iteration: 740 [23680/60000 (53%)]	 Batch 740 Loss: 0.267933
Train Epoch: 1 Iteration: 742 [23744/60000 (53%)]	 Batch 742 Loss: 0.539000
Train Epoch: 1 Iteration: 744 [23808/60000 (53%)]	 Batch 744 Loss: 0.230095
Train Epoch: 1 Iteration: 746 [23872/60000 (53%)]	 Batch 746 Loss: 0.186096
Train Epoch: 1 Iteration: 748 [23936/60000 (53%)]	 Batch 748 Loss: 0.228333
Train Epoch: 1 Iteration: 750 [24000/60000 (53%)]	 Batch 750 Loss: 0.363233
Train Epoch: 1 Iteration: 752 [24064/60000 (53%)]	 Batch 752 Loss: 0.284586
Train Epoch: 1 Iteration: 754 [24128/60000 (54%)]	 Batch 754 Loss: 0.051180
Train Epoch: 1 Iteration: 756 [24192/60000 (54%)]	 Batch 756 Loss: 0.205829
Train Epoch: 1 Iteration: 758 [24256/60000 (54%)]	 Batch 758 Loss: 0.080658
Train Epoch: 1 Iteration: 760 [24320/60000 (54%)]	 Batch 760 Loss: 0.316535
Train Epoch: 1 Iteration: 762 [24384/60000 (54%)]	 Batch 762 Loss: 0.182168
Train Epoch: 1 Iteration: 764 [24448/60000 (54%)]	 Batch 764 Loss: 0.180582
Train Epoch: 1 Iteration: 766 [24512/60000 (54%)]	 Batch 766 Loss: 0.019910
Train Epoch: 1 Iteration: 768 [24576/60000 (55%)]	 Batch 768 Loss: 0.278156
Train Epoch: 1 Iteration: 770 [24640/60000 (55%)]	 Batch 770 Loss: 0.122383
Train Epoch: 1 Iteration: 772 [24704/60000 (55%)]	 Batch 772 Loss: 0.523700
Train Epoch: 1 Iteration: 774 [24768/60000 (55%)]	 Batch 774 Loss: 0.743477
Train Epoch: 1 Iteration: 776 [24832/60000 (55%)]	 Batch 776 Loss: 0.168155
Train Epoch: 1 Iteration: 778 [24896/60000 (55%)]	 Batch 778 Loss: 0.336843
Train Epoch: 1 Iteration: 780 [24960/60000 (55%)]	 Batch 780 Loss: 0.011431
Train Epoch: 1 Iteration: 782 [25024/60000 (56%)]	 Batch 782 Loss: 0.761966
Train Epoch: 1 Iteration: 784 [25088/60000 (56%)]	 Batch 784 Loss: 0.032528
Train Epoch: 1 Iteration: 786 [25152/60000 (56%)]	 Batch 786 Loss: 0.229902
Train Epoch: 1 Iteration: 788 [25216/60000 (56%)]	 Batch 788 Loss: 0.335839
Train Epoch: 1 Iteration: 790 [25280/60000 (56%)]	 Batch 790 Loss: 0.193203
Train Epoch: 1 Iteration: 792 [25344/60000 (56%)]	 Batch 792 Loss: 0.207766
Train Epoch: 1 Iteration: 794 [25408/60000 (56%)]	 Batch 794 Loss: 0.280210
Train Epoch: 1 Iteration: 796 [25472/60000 (57%)]	 Batch 796 Loss: 0.180032
Train Epoch: 1 Iteration: 798 [25536/60000 (57%)]	 Batch 798 Loss: 0.386802
Train Epoch: 1 Iteration: 800 [25600/60000 (57%)]	 Batch 800 Loss: 0.261502
Train Epoch: 1 Iteration: 802 [25664/60000 (57%)]	 Batch 802 Loss: 0.095536
Train Epoch: 1 Iteration: 804 [25728/60000 (57%)]	 Batch 804 Loss: 0.143301
Train Epoch: 1 Iteration: 806 [25792/60000 (57%)]	 Batch 806 Loss: 0.046757
Train Epoch: 1 Iteration: 808 [25856/60000 (57%)]	 Batch 808 Loss: 0.284860
Train Epoch: 1 Iteration: 810 [25920/60000 (58%)]	 Batch 810 Loss: 0.196687
Train Epoch: 1 Iteration: 812 [25984/60000 (58%)]	 Batch 812 Loss: 0.160517
Train Epoch: 1 Iteration: 814 [26048/60000 (58%)]	 Batch 814 Loss: 0.264244
Train Epoch: 1 Iteration: 816 [26112/60000 (58%)]	 Batch 816 Loss: 0.020847
Train Epoch: 1 Iteration: 818 [26176/60000 (58%)]	 Batch 818 Loss: 0.082895
Train Epoch: 1 Iteration: 820 [26240/60000 (58%)]	 Batch 820 Loss: 0.291719
Train Epoch: 1 Iteration: 822 [26304/60000 (58%)]	 Batch 822 Loss: 0.054099
Train Epoch: 1 Iteration: 824 [26368/60000 (59%)]	 Batch 824 Loss: 0.824077
Train Epoch: 1 Iteration: 826 [26432/60000 (59%)]	 Batch 826 Loss: 0.470342
Train Epoch: 1 Iteration: 828 [26496/60000 (59%)]	 Batch 828 Loss: 0.095214
Train Epoch: 1 Iteration: 830 [26560/60000 (59%)]	 Batch 830 Loss: 0.322537
Train Epoch: 1 Iteration: 832 [26624/60000 (59%)]	 Batch 832 Loss: 0.117895
Train Epoch: 1 Iteration: 834 [26688/60000 (59%)]	 Batch 834 Loss: 0.409399
Train Epoch: 1 Iteration: 836 [26752/60000 (59%)]	 Batch 836 Loss: 0.064992
Train Epoch: 1 Iteration: 838 [26816/60000 (60%)]	 Batch 838 Loss: 0.140683
Train Epoch: 1 Iteration: 840 [26880/60000 (60%)]	 Batch 840 Loss: 0.160862
Train Epoch: 1 Iteration: 842 [26944/60000 (60%)]	 Batch 842 Loss: 0.200517
Train Epoch: 1 Iteration: 844 [27008/60000 (60%)]	 Batch 844 Loss: 0.205073
Train Epoch: 1 Iteration: 846 [27072/60000 (60%)]	 Batch 846 Loss: 0.049353
Train Epoch: 1 Iteration: 848 [27136/60000 (60%)]	 Batch 848 Loss: 0.111954
Train Epoch: 1 Iteration: 850 [27200/60000 (60%)]	 Batch 850 Loss: 0.165196
Train Epoch: 1 Iteration: 852 [27264/60000 (61%)]	 Batch 852 Loss: 0.240267
Train Epoch: 1 Iteration: 854 [27328/60000 (61%)]	 Batch 854 Loss: 0.378928
Train Epoch: 1 Iteration: 856 [27392/60000 (61%)]	 Batch 856 Loss: 0.128159
Train Epoch: 1 Iteration: 858 [27456/60000 (61%)]	 Batch 858 Loss: 0.024106
Train Epoch: 1 Iteration: 860 [27520/60000 (61%)]	 Batch 860 Loss: 0.077599
Train Epoch: 1 Iteration: 862 [27584/60000 (61%)]	 Batch 862 Loss: 0.316464
Train Epoch: 1 Iteration: 864 [27648/60000 (61%)]	 Batch 864 Loss: 0.204979
Train Epoch: 1 Iteration: 866 [27712/60000 (62%)]	 Batch 866 Loss: 0.212260
Train Epoch: 1 Iteration: 868 [27776/60000 (62%)]	 Batch 868 Loss: 0.494860
Train Epoch: 1 Iteration: 870 [27840/60000 (62%)]	 Batch 870 Loss: 0.601660
Train Epoch: 1 Iteration: 872 [27904/60000 (62%)]	 Batch 872 Loss: 0.340104
Train Epoch: 1 Iteration: 874 [27968/60000 (62%)]	 Batch 874 Loss: 0.252928
Train Epoch: 1 Iteration: 876 [28032/60000 (62%)]	 Batch 876 Loss: 0.241188
Train Epoch: 1 Iteration: 878 [28096/60000 (62%)]	 Batch 878 Loss: 0.342920
Train Epoch: 1 Iteration: 880 [28160/60000 (63%)]	 Batch 880 Loss: 0.078493
Train Epoch: 1 Iteration: 882 [28224/60000 (63%)]	 Batch 882 Loss: 0.216217
Train Epoch: 1 Iteration: 884 [28288/60000 (63%)]	 Batch 884 Loss: 0.169461
Train Epoch: 1 Iteration: 886 [28352/60000 (63%)]	 Batch 886 Loss: 0.175646
Train Epoch: 1 Iteration: 888 [28416/60000 (63%)]	 Batch 888 Loss: 0.319910
Train Epoch: 1 Iteration: 890 [28480/60000 (63%)]	 Batch 890 Loss: 0.267946
Train Epoch: 1 Iteration: 892 [28544/60000 (63%)]	 Batch 892 Loss: 0.137554
Train Epoch: 1 Iteration: 894 [28608/60000 (64%)]	 Batch 894 Loss: 0.130566
Train Epoch: 1 Iteration: 896 [28672/60000 (64%)]	 Batch 896 Loss: 0.063813
Train Epoch: 1 Iteration: 898 [28736/60000 (64%)]	 Batch 898 Loss: 0.225725
Train Epoch: 1 Iteration: 900 [28800/60000 (64%)]	 Batch 900 Loss: 0.034323
Train Epoch: 1 Iteration: 902 [28864/60000 (64%)]	 Batch 902 Loss: 0.119879
Train Epoch: 1 Iteration: 904 [28928/60000 (64%)]	 Batch 904 Loss: 0.113457
Train Epoch: 1 Iteration: 906 [28992/60000 (64%)]	 Batch 906 Loss: 0.198616
Train Epoch: 1 Iteration: 908 [29056/60000 (65%)]	 Batch 908 Loss: 0.107111
Train Epoch: 1 Iteration: 910 [29120/60000 (65%)]	 Batch 910 Loss: 0.144371
Train Epoch: 1 Iteration: 912 [29184/60000 (65%)]	 Batch 912 Loss: 0.037961
Train Epoch: 1 Iteration: 914 [29248/60000 (65%)]	 Batch 914 Loss: 0.079550
Train Epoch: 1 Iteration: 916 [29312/60000 (65%)]	 Batch 916 Loss: 0.034473
Train Epoch: 1 Iteration: 918 [29376/60000 (65%)]	 Batch 918 Loss: 0.715807
Train Epoch: 1 Iteration: 920 [29440/60000 (65%)]	 Batch 920 Loss: 0.055689
Train Epoch: 1 Iteration: 922 [29504/60000 (66%)]	 Batch 922 Loss: 0.124793
Train Epoch: 1 Iteration: 924 [29568/60000 (66%)]	 Batch 924 Loss: 0.340387
Train Epoch: 1 Iteration: 926 [29632/60000 (66%)]	 Batch 926 Loss: 0.066710
Train Epoch: 1 Iteration: 928 [29696/60000 (66%)]	 Batch 928 Loss: 0.125236
Train Epoch: 1 Iteration: 930 [29760/60000 (66%)]	 Batch 930 Loss: 0.394287
Train Epoch: 1 Iteration: 932 [29824/60000 (66%)]	 Batch 932 Loss: 0.402633
Train Epoch: 1 Iteration: 934 [29888/60000 (66%)]	 Batch 934 Loss: 0.056767
Train Epoch: 1 Iteration: 936 [29952/60000 (67%)]	 Batch 936 Loss: 0.086779
Train Epoch: 1 Iteration: 938 [30016/60000 (67%)]	 Batch 938 Loss: 0.372592
Train Epoch: 1 Iteration: 940 [30080/60000 (67%)]	 Batch 940 Loss: 0.128436
Train Epoch: 1 Iteration: 942 [30144/60000 (67%)]	 Batch 942 Loss: 0.087873
Train Epoch: 1 Iteration: 944 [30208/60000 (67%)]	 Batch 944 Loss: 0.508446
Train Epoch: 1 Iteration: 946 [30272/60000 (67%)]	 Batch 946 Loss: 0.191613
Train Epoch: 1 Iteration: 948 [30336/60000 (67%)]	 Batch 948 Loss: 0.052776
Train Epoch: 1 Iteration: 950 [30400/60000 (68%)]	 Batch 950 Loss: 0.190588
Train Epoch: 1 Iteration: 952 [30464/60000 (68%)]	 Batch 952 Loss: 0.209045
Train Epoch: 1 Iteration: 954 [30528/60000 (68%)]	 Batch 954 Loss: 0.269146
Train Epoch: 1 Iteration: 956 [30592/60000 (68%)]	 Batch 956 Loss: 0.169059
Train Epoch: 1 Iteration: 958 [30656/60000 (68%)]	 Batch 958 Loss: 0.247974
Train Epoch: 1 Iteration: 960 [30720/60000 (68%)]	 Batch 960 Loss: 0.271229
Train Epoch: 1 Iteration: 962 [30784/60000 (68%)]	 Batch 962 Loss: 0.049882
Train Epoch: 1 Iteration: 964 [30848/60000 (69%)]	 Batch 964 Loss: 0.276356
Train Epoch: 1 Iteration: 966 [30912/60000 (69%)]	 Batch 966 Loss: 0.166735
Train Epoch: 1 Iteration: 968 [30976/60000 (69%)]	 Batch 968 Loss: 0.057304
Train Epoch: 1 Iteration: 970 [31040/60000 (69%)]	 Batch 970 Loss: 0.062828
Train Epoch: 1 Iteration: 972 [31104/60000 (69%)]	 Batch 972 Loss: 0.287152
Train Epoch: 1 Iteration: 974 [31168/60000 (69%)]	 Batch 974 Loss: 0.407334
Train Epoch: 1 Iteration: 976 [31232/60000 (69%)]	 Batch 976 Loss: 0.295525
Train Epoch: 1 Iteration: 978 [31296/60000 (70%)]	 Batch 978 Loss: 0.020492
Train Epoch: 1 Iteration: 980 [31360/60000 (70%)]	 Batch 980 Loss: 0.401326
Train Epoch: 1 Iteration: 982 [31424/60000 (70%)]	 Batch 982 Loss: 0.039433
Train Epoch: 1 Iteration: 984 [31488/60000 (70%)]	 Batch 984 Loss: 0.197562
Train Epoch: 1 Iteration: 986 [31552/60000 (70%)]	 Batch 986 Loss: 0.055886
Train Epoch: 1 Iteration: 988 [31616/60000 (70%)]	 Batch 988 Loss: 0.079764
Train Epoch: 1 Iteration: 990 [31680/60000 (70%)]	 Batch 990 Loss: 0.398091
Train Epoch: 1 Iteration: 992 [31744/60000 (71%)]	 Batch 992 Loss: 0.167069
Train Epoch: 1 Iteration: 994 [31808/60000 (71%)]	 Batch 994 Loss: 0.146940
Train Epoch: 1 Iteration: 996 [31872/60000 (71%)]	 Batch 996 Loss: 0.018735
Train Epoch: 1 Iteration: 998 [31936/60000 (71%)]	 Batch 998 Loss: 0.320438
Train Epoch: 1 Iteration: 1000 [32000/60000 (71%)]	 Batch 1000 Loss: 0.391319
Train Epoch: 1 Iteration: 1002 [32064/60000 (71%)]	 Batch 1002 Loss: 0.311850
Train Epoch: 1 Iteration: 1004 [32128/60000 (71%)]	 Batch 1004 Loss: 0.221492
Train Epoch: 1 Iteration: 1006 [32192/60000 (71%)]	 Batch 1006 Loss: 0.208641
Train Epoch: 1 Iteration: 1008 [32256/60000 (72%)]	 Batch 1008 Loss: 0.297260
Train Epoch: 1 Iteration: 1010 [32320/60000 (72%)]	 Batch 1010 Loss: 0.233965
Train Epoch: 1 Iteration: 1012 [32384/60000 (72%)]	 Batch 1012 Loss: 0.155005
Train Epoch: 1 Iteration: 1014 [32448/60000 (72%)]	 Batch 1014 Loss: 0.027547
Train Epoch: 1 Iteration: 1016 [32512/60000 (72%)]	 Batch 1016 Loss: 0.313489
Train Epoch: 1 Iteration: 1018 [32576/60000 (72%)]	 Batch 1018 Loss: 0.180325
Train Epoch: 1 Iteration: 1020 [32640/60000 (72%)]	 Batch 1020 Loss: 0.251628
Train Epoch: 1 Iteration: 1022 [32704/60000 (73%)]	 Batch 1022 Loss: 0.199272
Train Epoch: 1 Iteration: 1024 [32768/60000 (73%)]	 Batch 1024 Loss: 0.126267
Train Epoch: 1 Iteration: 1026 [32832/60000 (73%)]	 Batch 1026 Loss: 0.189598
Train Epoch: 1 Iteration: 1028 [32896/60000 (73%)]	 Batch 1028 Loss: 0.029467
Train Epoch: 1 Iteration: 1030 [32960/60000 (73%)]	 Batch 1030 Loss: 0.040759
Train Epoch: 1 Iteration: 1032 [33024/60000 (73%)]	 Batch 1032 Loss: 0.221002
Train Epoch: 1 Iteration: 1034 [33088/60000 (73%)]	 Batch 1034 Loss: 0.088618
Train Epoch: 1 Iteration: 1036 [33152/60000 (74%)]	 Batch 1036 Loss: 0.103947
Train Epoch: 1 Iteration: 1038 [33216/60000 (74%)]	 Batch 1038 Loss: 0.089241
Train Epoch: 1 Iteration: 1040 [33280/60000 (74%)]	 Batch 1040 Loss: 0.386603
Train Epoch: 1 Iteration: 1042 [33344/60000 (74%)]	 Batch 1042 Loss: 0.019159
Train Epoch: 1 Iteration: 1044 [33408/60000 (74%)]	 Batch 1044 Loss: 0.347262
Train Epoch: 1 Iteration: 1046 [33472/60000 (74%)]	 Batch 1046 Loss: 0.104552
Train Epoch: 1 Iteration: 1048 [33536/60000 (74%)]	 Batch 1048 Loss: 0.173231
Train Epoch: 1 Iteration: 1050 [33600/60000 (75%)]	 Batch 1050 Loss: 0.178401
Train Epoch: 1 Iteration: 1052 [33664/60000 (75%)]	 Batch 1052 Loss: 0.183523
Train Epoch: 1 Iteration: 1054 [33728/60000 (75%)]	 Batch 1054 Loss: 0.055293
Train Epoch: 1 Iteration: 1056 [33792/60000 (75%)]	 Batch 1056 Loss: 0.102227
Train Epoch: 1 Iteration: 1058 [33856/60000 (75%)]	 Batch 1058 Loss: 0.113615
Train Epoch: 1 Iteration: 1060 [33920/60000 (75%)]	 Batch 1060 Loss: 0.266610
Train Epoch: 1 Iteration: 1062 [33984/60000 (75%)]	 Batch 1062 Loss: 0.286644
Train Epoch: 1 Iteration: 1064 [34048/60000 (76%)]	 Batch 1064 Loss: 0.263071
Train Epoch: 1 Iteration: 1066 [34112/60000 (76%)]	 Batch 1066 Loss: 0.018299
Train Epoch: 1 Iteration: 1068 [34176/60000 (76%)]	 Batch 1068 Loss: 0.214498
Train Epoch: 1 Iteration: 1070 [34240/60000 (76%)]	 Batch 1070 Loss: 0.115322
Train Epoch: 1 Iteration: 1072 [34304/60000 (76%)]	 Batch 1072 Loss: 0.181721
Train Epoch: 1 Iteration: 1074 [34368/60000 (76%)]	 Batch 1074 Loss: 0.175845
Train Epoch: 1 Iteration: 1076 [34432/60000 (76%)]	 Batch 1076 Loss: 0.037455
Train Epoch: 1 Iteration: 1078 [34496/60000 (77%)]	 Batch 1078 Loss: 0.402736
Train Epoch: 1 Iteration: 1080 [34560/60000 (77%)]	 Batch 1080 Loss: 0.223585
Train Epoch: 1 Iteration: 1082 [34624/60000 (77%)]	 Batch 1082 Loss: 0.282721
Train Epoch: 1 Iteration: 1084 [34688/60000 (77%)]	 Batch 1084 Loss: 0.097566
Train Epoch: 1 Iteration: 1086 [34752/60000 (77%)]	 Batch 1086 Loss: 0.037381
Train Epoch: 1 Iteration: 1088 [34816/60000 (77%)]	 Batch 1088 Loss: 0.272879
Train Epoch: 1 Iteration: 1090 [34880/60000 (77%)]	 Batch 1090 Loss: 0.305302
Train Epoch: 1 Iteration: 1092 [34944/60000 (78%)]	 Batch 1092 Loss: 0.047868
Train Epoch: 1 Iteration: 1094 [35008/60000 (78%)]	 Batch 1094 Loss: 0.161093
Train Epoch: 1 Iteration: 1096 [35072/60000 (78%)]	 Batch 1096 Loss: 0.101447
Train Epoch: 1 Iteration: 1098 [35136/60000 (78%)]	 Batch 1098 Loss: 0.081517
Train Epoch: 1 Iteration: 1100 [35200/60000 (78%)]	 Batch 1100 Loss: 0.230768
Train Epoch: 1 Iteration: 1102 [35264/60000 (78%)]	 Batch 1102 Loss: 0.240940
Train Epoch: 1 Iteration: 1104 [35328/60000 (78%)]	 Batch 1104 Loss: 0.251771
Train Epoch: 1 Iteration: 1106 [35392/60000 (79%)]	 Batch 1106 Loss: 0.349706
Train Epoch: 1 Iteration: 1108 [35456/60000 (79%)]	 Batch 1108 Loss: 0.078002
Train Epoch: 1 Iteration: 1110 [35520/60000 (79%)]	 Batch 1110 Loss: 0.304626
Train Epoch: 1 Iteration: 1112 [35584/60000 (79%)]	 Batch 1112 Loss: 0.236800
Train Epoch: 1 Iteration: 1114 [35648/60000 (79%)]	 Batch 1114 Loss: 0.229264
Train Epoch: 1 Iteration: 1116 [35712/60000 (79%)]	 Batch 1116 Loss: 0.401135
Train Epoch: 1 Iteration: 1118 [35776/60000 (79%)]	 Batch 1118 Loss: 0.234891
Train Epoch: 1 Iteration: 1120 [35840/60000 (80%)]	 Batch 1120 Loss: 0.125382
Train Epoch: 1 Iteration: 1122 [35904/60000 (80%)]	 Batch 1122 Loss: 0.039411
Train Epoch: 1 Iteration: 1124 [35968/60000 (80%)]	 Batch 1124 Loss: 0.307446
Train Epoch: 1 Iteration: 1126 [36032/60000 (80%)]	 Batch 1126 Loss: 0.441148
Train Epoch: 1 Iteration: 1128 [36096/60000 (80%)]	 Batch 1128 Loss: 0.279208
Train Epoch: 1 Iteration: 1130 [36160/60000 (80%)]	 Batch 1130 Loss: 0.129079
Train Epoch: 1 Iteration: 1132 [36224/60000 (80%)]	 Batch 1132 Loss: 0.040551
Train Epoch: 1 Iteration: 1134 [36288/60000 (81%)]	 Batch 1134 Loss: 0.146492
Train Epoch: 1 Iteration: 1136 [36352/60000 (81%)]	 Batch 1136 Loss: 0.047953
Train Epoch: 1 Iteration: 1138 [36416/60000 (81%)]	 Batch 1138 Loss: 0.056767
Train Epoch: 1 Iteration: 1140 [36480/60000 (81%)]	 Batch 1140 Loss: 0.519102
Train Epoch: 1 Iteration: 1142 [36544/60000 (81%)]	 Batch 1142 Loss: 0.131452
Train Epoch: 1 Iteration: 1144 [36608/60000 (81%)]	 Batch 1144 Loss: 0.354873
Train Epoch: 1 Iteration: 1146 [36672/60000 (81%)]	 Batch 1146 Loss: 0.303267
Train Epoch: 1 Iteration: 1148 [36736/60000 (82%)]	 Batch 1148 Loss: 0.108344
Train Epoch: 1 Iteration: 1150 [36800/60000 (82%)]	 Batch 1150 Loss: 0.582339
Train Epoch: 1 Iteration: 1152 [36864/60000 (82%)]	 Batch 1152 Loss: 0.027098
Train Epoch: 1 Iteration: 1154 [36928/60000 (82%)]	 Batch 1154 Loss: 0.416934
Train Epoch: 1 Iteration: 1156 [36992/60000 (82%)]	 Batch 1156 Loss: 0.393673
Train Epoch: 1 Iteration: 1158 [37056/60000 (82%)]	 Batch 1158 Loss: 0.219137
Train Epoch: 1 Iteration: 1160 [37120/60000 (82%)]	 Batch 1160 Loss: 0.403871
Train Epoch: 1 Iteration: 1162 [37184/60000 (83%)]	 Batch 1162 Loss: 0.160458
Train Epoch: 1 Iteration: 1164 [37248/60000 (83%)]	 Batch 1164 Loss: 0.267195
Train Epoch: 1 Iteration: 1166 [37312/60000 (83%)]	 Batch 1166 Loss: 0.455546
Train Epoch: 1 Iteration: 1168 [37376/60000 (83%)]	 Batch 1168 Loss: 0.347547
Train Epoch: 1 Iteration: 1170 [37440/60000 (83%)]	 Batch 1170 Loss: 0.234513
Train Epoch: 1 Iteration: 1172 [37504/60000 (83%)]	 Batch 1172 Loss: 0.141409
Train Epoch: 1 Iteration: 1174 [37568/60000 (83%)]	 Batch 1174 Loss: 0.197614
Train Epoch: 1 Iteration: 1176 [37632/60000 (84%)]	 Batch 1176 Loss: 0.384855
Train Epoch: 1 Iteration: 1178 [37696/60000 (84%)]	 Batch 1178 Loss: 0.139269
Train Epoch: 1 Iteration: 1180 [37760/60000 (84%)]	 Batch 1180 Loss: 0.231062
Train Epoch: 1 Iteration: 1182 [37824/60000 (84%)]	 Batch 1182 Loss: 0.110559
Train Epoch: 1 Iteration: 1184 [37888/60000 (84%)]	 Batch 1184 Loss: 0.334357
Train Epoch: 1 Iteration: 1186 [37952/60000 (84%)]	 Batch 1186 Loss: 0.235485
Train Epoch: 1 Iteration: 1188 [38016/60000 (84%)]	 Batch 1188 Loss: 0.438576
Train Epoch: 1 Iteration: 1190 [38080/60000 (85%)]	 Batch 1190 Loss: 0.132379
Train Epoch: 1 Iteration: 1192 [38144/60000 (85%)]	 Batch 1192 Loss: 0.133811
Train Epoch: 1 Iteration: 1194 [38208/60000 (85%)]	 Batch 1194 Loss: 0.350531
Train Epoch: 1 Iteration: 1196 [38272/60000 (85%)]	 Batch 1196 Loss: 0.086625
Train Epoch: 1 Iteration: 1198 [38336/60000 (85%)]	 Batch 1198 Loss: 0.511278
Train Epoch: 1 Iteration: 1200 [38400/60000 (85%)]	 Batch 1200 Loss: 0.166526
Train Epoch: 1 Iteration: 1202 [38464/60000 (85%)]	 Batch 1202 Loss: 0.214450
Train Epoch: 1 Iteration: 1204 [38528/60000 (86%)]	 Batch 1204 Loss: 0.306629
Train Epoch: 1 Iteration: 1206 [38592/60000 (86%)]	 Batch 1206 Loss: 0.167628
Train Epoch: 1 Iteration: 1208 [38656/60000 (86%)]	 Batch 1208 Loss: 0.091275
Train Epoch: 1 Iteration: 1210 [38720/60000 (86%)]	 Batch 1210 Loss: 0.279659
Train Epoch: 1 Iteration: 1212 [38784/60000 (86%)]	 Batch 1212 Loss: 0.345316
Train Epoch: 1 Iteration: 1214 [38848/60000 (86%)]	 Batch 1214 Loss: 0.309693
Train Epoch: 1 Iteration: 1216 [38912/60000 (86%)]	 Batch 1216 Loss: 0.399292
Train Epoch: 1 Iteration: 1218 [38976/60000 (87%)]	 Batch 1218 Loss: 0.110461
Train Epoch: 1 Iteration: 1220 [39040/60000 (87%)]	 Batch 1220 Loss: 0.220664
Train Epoch: 1 Iteration: 1222 [39104/60000 (87%)]	 Batch 1222 Loss: 0.166692
Train Epoch: 1 Iteration: 1224 [39168/60000 (87%)]	 Batch 1224 Loss: 0.381728
Train Epoch: 1 Iteration: 1226 [39232/60000 (87%)]	 Batch 1226 Loss: 0.205901
Train Epoch: 1 Iteration: 1228 [39296/60000 (87%)]	 Batch 1228 Loss: 0.145294
Train Epoch: 1 Iteration: 1230 [39360/60000 (87%)]	 Batch 1230 Loss: 0.490530
Train Epoch: 1 Iteration: 1232 [39424/60000 (88%)]	 Batch 1232 Loss: 0.025614
Train Epoch: 1 Iteration: 1234 [39488/60000 (88%)]	 Batch 1234 Loss: 0.417321
Train Epoch: 1 Iteration: 1236 [39552/60000 (88%)]	 Batch 1236 Loss: 0.125153
Train Epoch: 1 Iteration: 1238 [39616/60000 (88%)]	 Batch 1238 Loss: 0.591685
Train Epoch: 1 Iteration: 1240 [39680/60000 (88%)]	 Batch 1240 Loss: 0.519055
Train Epoch: 1 Iteration: 1242 [39744/60000 (88%)]	 Batch 1242 Loss: 0.266289
Train Epoch: 1 Iteration: 1244 [39808/60000 (88%)]	 Batch 1244 Loss: 0.243395
Train Epoch: 1 Iteration: 1246 [39872/60000 (89%)]	 Batch 1246 Loss: 0.126151
Train Epoch: 1 Iteration: 1248 [39936/60000 (89%)]	 Batch 1248 Loss: 0.237700
Train Epoch: 1 Iteration: 1250 [40000/60000 (89%)]	 Batch 1250 Loss: 0.297224
Train Epoch: 1 Iteration: 1252 [40064/60000 (89%)]	 Batch 1252 Loss: 0.431930
Train Epoch: 1 Iteration: 1254 [40128/60000 (89%)]	 Batch 1254 Loss: 0.683366
Train Epoch: 1 Iteration: 1256 [40192/60000 (89%)]	 Batch 1256 Loss: 0.144100
Train Epoch: 1 Iteration: 1258 [40256/60000 (89%)]	 Batch 1258 Loss: 0.195309
Train Epoch: 1 Iteration: 1260 [40320/60000 (90%)]	 Batch 1260 Loss: 0.385274
Train Epoch: 1 Iteration: 1262 [40384/60000 (90%)]	 Batch 1262 Loss: 0.388572
Train Epoch: 1 Iteration: 1264 [40448/60000 (90%)]	 Batch 1264 Loss: 0.431780
Train Epoch: 1 Iteration: 1266 [40512/60000 (90%)]	 Batch 1266 Loss: 0.409558
Train Epoch: 1 Iteration: 1268 [40576/60000 (90%)]	 Batch 1268 Loss: 0.224910
Train Epoch: 1 Iteration: 1270 [40640/60000 (90%)]	 Batch 1270 Loss: 0.243689
Train Epoch: 1 Iteration: 1272 [40704/60000 (90%)]	 Batch 1272 Loss: 0.480327
Train Epoch: 1 Iteration: 1274 [40768/60000 (91%)]	 Batch 1274 Loss: 0.276364
Train Epoch: 1 Iteration: 1276 [40832/60000 (91%)]	 Batch 1276 Loss: 0.128429
Train Epoch: 1 Iteration: 1278 [40896/60000 (91%)]	 Batch 1278 Loss: 0.202247
Train Epoch: 1 Iteration: 1280 [40960/60000 (91%)]	 Batch 1280 Loss: 0.086088
Train Epoch: 1 Iteration: 1282 [41024/60000 (91%)]	 Batch 1282 Loss: 0.082414
Train Epoch: 1 Iteration: 1284 [41088/60000 (91%)]	 Batch 1284 Loss: 0.254985
Train Epoch: 1 Iteration: 1286 [41152/60000 (91%)]	 Batch 1286 Loss: 0.161377
Train Epoch: 1 Iteration: 1288 [41216/60000 (92%)]	 Batch 1288 Loss: 0.361092
Train Epoch: 1 Iteration: 1290 [41280/60000 (92%)]	 Batch 1290 Loss: 0.200654
Train Epoch: 1 Iteration: 1292 [41344/60000 (92%)]	 Batch 1292 Loss: 0.144365
Train Epoch: 1 Iteration: 1294 [41408/60000 (92%)]	 Batch 1294 Loss: 0.112840
Train Epoch: 1 Iteration: 1296 [41472/60000 (92%)]	 Batch 1296 Loss: 0.778475
Train Epoch: 1 Iteration: 1298 [41536/60000 (92%)]	 Batch 1298 Loss: 0.026626
Train Epoch: 1 Iteration: 1300 [41600/60000 (92%)]	 Batch 1300 Loss: 0.349787
Train Epoch: 1 Iteration: 1302 [41664/60000 (93%)]	 Batch 1302 Loss: 0.064465
Train Epoch: 1 Iteration: 1304 [41728/60000 (93%)]	 Batch 1304 Loss: 0.137651
Train Epoch: 1 Iteration: 1306 [41792/60000 (93%)]	 Batch 1306 Loss: 0.193478
Train Epoch: 1 Iteration: 1308 [41856/60000 (93%)]	 Batch 1308 Loss: 0.214228
Train Epoch: 1 Iteration: 1310 [41920/60000 (93%)]	 Batch 1310 Loss: 0.166364
Train Epoch: 1 Iteration: 1312 [41984/60000 (93%)]	 Batch 1312 Loss: 0.126752
Train Epoch: 1 Iteration: 1314 [42048/60000 (93%)]	 Batch 1314 Loss: 0.019214
Train Epoch: 1 Iteration: 1316 [42112/60000 (94%)]	 Batch 1316 Loss: 0.071055
Train Epoch: 1 Iteration: 1318 [42176/60000 (94%)]	 Batch 1318 Loss: 0.519398
Train Epoch: 1 Iteration: 1320 [42240/60000 (94%)]	 Batch 1320 Loss: 0.124848
Train Epoch: 1 Iteration: 1322 [42304/60000 (94%)]	 Batch 1322 Loss: 0.009682
Train Epoch: 1 Iteration: 1324 [42368/60000 (94%)]	 Batch 1324 Loss: 0.356182
Train Epoch: 1 Iteration: 1326 [42432/60000 (94%)]	 Batch 1326 Loss: 0.067374
Train Epoch: 1 Iteration: 1328 [42496/60000 (94%)]	 Batch 1328 Loss: 0.108485
Train Epoch: 1 Iteration: 1330 [42560/60000 (95%)]	 Batch 1330 Loss: 0.109947
Train Epoch: 1 Iteration: 1332 [42624/60000 (95%)]	 Batch 1332 Loss: 0.411520
Train Epoch: 1 Iteration: 1334 [42688/60000 (95%)]	 Batch 1334 Loss: 0.333329
Train Epoch: 1 Iteration: 1336 [42752/60000 (95%)]	 Batch 1336 Loss: 0.279607
Train Epoch: 1 Iteration: 1338 [42816/60000 (95%)]	 Batch 1338 Loss: 0.240556
Train Epoch: 1 Iteration: 1340 [42880/60000 (95%)]	 Batch 1340 Loss: 0.243391
Train Epoch: 1 Iteration: 1342 [42944/60000 (95%)]	 Batch 1342 Loss: 0.130032
Train Epoch: 1 Iteration: 1344 [43008/60000 (96%)]	 Batch 1344 Loss: 0.187029
Train Epoch: 1 Iteration: 1346 [43072/60000 (96%)]	 Batch 1346 Loss: 0.371469
Train Epoch: 1 Iteration: 1348 [43136/60000 (96%)]	 Batch 1348 Loss: 0.208107
Train Epoch: 1 Iteration: 1350 [43200/60000 (96%)]	 Batch 1350 Loss: 0.275423
Train Epoch: 1 Iteration: 1352 [43264/60000 (96%)]	 Batch 1352 Loss: 0.056218
Train Epoch: 1 Iteration: 1354 [43328/60000 (96%)]	 Batch 1354 Loss: 0.187842
Train Epoch: 1 Iteration: 1356 [43392/60000 (96%)]	 Batch 1356 Loss: 0.208147
Train Epoch: 1 Iteration: 1358 [43456/60000 (97%)]	 Batch 1358 Loss: 0.220325
Train Epoch: 1 Iteration: 1360 [43520/60000 (97%)]	 Batch 1360 Loss: 0.195752
Train Epoch: 1 Iteration: 1362 [43584/60000 (97%)]	 Batch 1362 Loss: 0.090230
Train Epoch: 1 Iteration: 1364 [43648/60000 (97%)]	 Batch 1364 Loss: 0.136934
Train Epoch: 1 Iteration: 1366 [43712/60000 (97%)]	 Batch 1366 Loss: 0.036913
Train Epoch: 1 Iteration: 1368 [43776/60000 (97%)]	 Batch 1368 Loss: 0.228344
Train Epoch: 1 Iteration: 1370 [43840/60000 (97%)]	 Batch 1370 Loss: 0.107939
Train Epoch: 1 Iteration: 1372 [43904/60000 (98%)]	 Batch 1372 Loss: 0.174453
Train Epoch: 1 Iteration: 1374 [43968/60000 (98%)]	 Batch 1374 Loss: 0.093442
Train Epoch: 1 Iteration: 1376 [44032/60000 (98%)]	 Batch 1376 Loss: 0.029952
Train Epoch: 1 Iteration: 1378 [44096/60000 (98%)]	 Batch 1378 Loss: 0.256607
Train Epoch: 1 Iteration: 1380 [44160/60000 (98%)]	 Batch 1380 Loss: 0.261673
Train Epoch: 1 Iteration: 1382 [44224/60000 (98%)]	 Batch 1382 Loss: 0.335735
Train Epoch: 1 Iteration: 1384 [44288/60000 (98%)]	 Batch 1384 Loss: 0.180579
Train Epoch: 1 Iteration: 1386 [44352/60000 (99%)]	 Batch 1386 Loss: 0.174416
Train Epoch: 1 Iteration: 1388 [44416/60000 (99%)]	 Batch 1388 Loss: 0.022693
Train Epoch: 1 Iteration: 1390 [44480/60000 (99%)]	 Batch 1390 Loss: 0.083220
Train Epoch: 1 Iteration: 1392 [44544/60000 (99%)]	 Batch 1392 Loss: 0.420979
Train Epoch: 1 Iteration: 1394 [44608/60000 (99%)]	 Batch 1394 Loss: 0.058691
Train Epoch: 1 Iteration: 1396 [44672/60000 (99%)]	 Batch 1396 Loss: 0.040889
Train Epoch: 1 Iteration: 1398 [44736/60000 (99%)]	 Batch 1398 Loss: 0.059643
Train Epoch: 1 Iteration: 1400 [44800/60000 (100%)]	 Batch 1400 Loss: 0.160568
Train Epoch: 1 Iteration: 1402 [44864/60000 (100%)]	 Batch 1402 Loss: 0.176669
Train Epoch: 1 Iteration: 1404 [44928/60000 (100%)]	 Batch 1404 Loss: 0.103870
Train Epoch: 1 Iteration: 1406 [44992/60000 (100%)]	 Batch 1406 Loss: 0.012741


----------------- Epoch 1 -----------------

15000
================================ QUIT ================================
 Saving Model ...
15000
