============================ Raw Args ============================
Namespace(batch_size=64, classification='y', dropout='n', dropout_prob=0.0, gpu_i=-1, imbalanced_sampler='y', k_folds='5', l2_reg='n', load_trained='n', log_dest='../models/ObjectClassifier128_Faces-2021-10-10_20-23-16', loss_freq=100, lr=0.005, model_name='ObjectClassifier128', normalize='y', num_classes=2, num_epochs=1, optim='SGD', regression='n', root_dir='none', session_name='ObjectClassifier128_Faces', test_data_dir='none', test_labels_csv='none', train_data_dir='none', train_labels_csv='none', trained_path='../models/PMR_detection_0-3_two_to_one-2021-09-01_12-09-14/BEST_model.pth', val_freq=0, weight_decay_amnt=0.0, weighted_loss='n')



================================ Start Training ================================

Session Name: ObjectClassifier128_Faces

Model Name: ObjectClassifier128
Device: cpu

Hyperparameters:
Batch Size: 64
Learning Rate: 0.005
Number of Epochs: 1
Normalization:y


FOLD 0
=================================================================
0.0
0.000983942065491184
0.001967884130982368
0.0029518261964735517
0.003935768261964736
0.004919710327455919
0.005903652392947103
0.006887594458438287
0.007871536523929471
0.008855478589420655
0.009839420654911838
0.010823362720403023
0.011807304785894207
0.01279124685138539
0.013775188916876574
0.014759130982367759
0.015743073047858942
0.016727015113350126
0.01771095717884131
0.018694899244332493
0.019678841309823676
0.020662783375314863
0.021646725440806047
0.02263066750629723
0.023614609571788413
0.024598551637279597
0.02558249370277078
0.026566435768261964
0.027550377833753147
0.028534319899244334
0.029518261964735518
0.0305022040302267
0.031486146095717885
0.03247008816120907
0.03345403022670025
0.034437972292191435
0.03542191435768262
0.0364058564231738
0.037389798488664985
0.03837374055415617
0.03935768261964735
0.040341624685138536
0.041325566750629726
0.04230950881612091
0.04329345088161209
0.044277392947103276
0.04526133501259446
0.04624527707808564
0.04722921914357683
0.04821316120906801
0.049197103274559194
0.05018104534005038
0.05116498740554156
0.052148929471032744
0.05313287153652393
0.05411681360201511
0.055100755667506295
0.05608469773299748
0.05706863979848867
0.05805258186397985
0.059036523929471035
0.06002046599496222
0.0610044080604534
0.061988350125944586
0.06297229219143577
0.06395623425692695
0.06494017632241814
0.06592411838790932
0.0669080604534005
0.06789200251889169
0.06887594458438287
================================ QUIT ================================
 Saving Model ...
